{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Reading-the-data\" data-toc-modified-id=\"Reading-the-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Reading the data</a></span></li><li><span><a href=\"#Processing-the-data\" data-toc-modified-id=\"Processing-the-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Processing the data</a></span></li><li><span><a href=\"#Splitting-the-data--:-local-holdout-test-set\" data-toc-modified-id=\"Splitting-the-data--:-local-holdout-test-set-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Splitting the data  : local holdout test set</a></span></li><li><span><a href=\"#Data-analysis\" data-toc-modified-id=\"Data-analysis-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#word-frequencies\" data-toc-modified-id=\"word-frequencies-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>word frequencies</a></span></li><li><span><a href=\"#sentence-frequencies\" data-toc-modified-id=\"sentence-frequencies-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>sentence frequencies</a></span></li><li><span><a href=\"#hyperlinks-analysis\" data-toc-modified-id=\"hyperlinks-analysis-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>hyperlinks analysis</a></span></li><li><span><a href=\"#&quot;Pure&quot;-nodes-to-include-in-training\" data-toc-modified-id=\"&quot;Pure&quot;-nodes-to-include-in-training-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>\"Pure\" nodes to include in training</a></span></li></ul></li><li><span><a href=\"#Check-vocabulary-coverage\" data-toc-modified-id=\"Check-vocabulary-coverage-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Check vocabulary coverage</a></span></li><li><span><a href=\"#Trying-CamemBERT\" data-toc-modified-id=\"Trying-CamemBERT-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Trying CamemBERT</a></span><ul class=\"toc-item\"><li><span><a href=\"#Concatenate-SVD-reducted-tfidf-with-approach-3\" data-toc-modified-id=\"Concatenate-SVD-reducted-tfidf-with-approach-3-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Concatenate SVD reducted tfidf with approach 3</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogReg\" data-toc-modified-id=\"LogReg-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>LogReg</a></span></li><li><span><a href=\"#SVM\" data-toc-modified-id=\"SVM-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>SVM</a></span></li><li><span><a href=\"#SVD-reducted-concatenated-matrix-from-6.1\" data-toc-modified-id=\"SVD-reducted-concatenated-matrix-from-6.1-6.1.3\"><span class=\"toc-item-num\">6.1.3&nbsp;&nbsp;</span>SVD reducted concatenated matrix from 6.1</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogReg\" data-toc-modified-id=\"LogReg-6.1.3.1\"><span class=\"toc-item-num\">6.1.3.1&nbsp;&nbsp;</span>LogReg</a></span></li><li><span><a href=\"#SVM\" data-toc-modified-id=\"SVM-6.1.3.2\"><span class=\"toc-item-num\">6.1.3.2&nbsp;&nbsp;</span>SVM</a></span></li></ul></li><li><span><a href=\"#Concatenate-just-ater-tfidf-then-apply-SVD\" data-toc-modified-id=\"Concatenate-just-ater-tfidf-then-apply-SVD-6.1.4\"><span class=\"toc-item-num\">6.1.4&nbsp;&nbsp;</span>Concatenate just ater tfidf then apply SVD</a></span></li></ul></li><li><span><a href=\"#Approach-3-with-SVM\" data-toc-modified-id=\"Approach-3-with-SVM-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Approach 3 with SVM</a></span></li><li><span><a href=\"#Approach-3\" data-toc-modified-id=\"Approach-3-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Approach 3</a></span></li><li><span><a href=\"#Approach-2\" data-toc-modified-id=\"Approach-2-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Approach 2</a></span></li><li><span><a href=\"#Approach-1-:\" data-toc-modified-id=\"Approach-1-:-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Approach 1 :</a></span></li></ul></li><li><span><a href=\"#Trying-tfidf\" data-toc-modified-id=\"Trying-tfidf-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Trying tfidf</a></span><ul class=\"toc-item\"><li><span><a href=\"#SVM\" data-toc-modified-id=\"SVM-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>SVM</a></span></li><li><span><a href=\"#LogReg\" data-toc-modified-id=\"LogReg-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>LogReg</a></span></li><li><span><a href=\"#SVD-+-SVM\" data-toc-modified-id=\"SVD-+-SVM-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>SVD + SVM</a></span><ul class=\"toc-item\"><li><span><a href=\"#Approach-1-:\" data-toc-modified-id=\"Approach-1-:-7.3.1\"><span class=\"toc-item-num\">7.3.1&nbsp;&nbsp;</span>Approach 1 :</a></span></li><li><span><a href=\"#Approach-5\" data-toc-modified-id=\"Approach-5-7.3.2\"><span class=\"toc-item-num\">7.3.2&nbsp;&nbsp;</span>Approach 5</a></span></li><li><span><a href=\"#Approach-4\" data-toc-modified-id=\"Approach-4-7.3.3\"><span class=\"toc-item-num\">7.3.3&nbsp;&nbsp;</span>Approach 4</a></span></li><li><span><a href=\"#Approach-3-:\" data-toc-modified-id=\"Approach-3-:-7.3.4\"><span class=\"toc-item-num\">7.3.4&nbsp;&nbsp;</span>Approach 3 :</a></span></li><li><span><a href=\"#Approach-2-:\" data-toc-modified-id=\"Approach-2-:-7.3.5\"><span class=\"toc-item-num\">7.3.5&nbsp;&nbsp;</span>Approach 2 :</a></span></li></ul></li><li><span><a href=\"#SVD-+-LogReg\" data-toc-modified-id=\"SVD-+-LogReg-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>SVD + LogReg</a></span></li><li><span><a href=\"#SVD-+-NN-classifier\" data-toc-modified-id=\"SVD-+-NN-classifier-7.5\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>SVD + NN classifier</a></span></li></ul></li><li><span><a href=\"#Tfidf-features-+-GNN\" data-toc-modified-id=\"Tfidf-features-+-GNN-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Tfidf features + GNN</a></span></li><li><span><a href=\"#Trying-a-bi-LSTM\" data-toc-modified-id=\"Trying-a-bi-LSTM-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Trying a bi-LSTM</a></span></li><li><span><a href=\"#Analysis-of-the-predictions\" data-toc-modified-id=\"Analysis-of-the-predictions-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Analysis of the predictions</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *\n",
    "from Preprocessing.preprocessing_text import *\n",
    "from feature_extractor.build_features import *\n",
    "from models.models import *\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./data/train_noduplicates.csv\" \n",
    "test_path = \"./data/test.csv\"\n",
    "\n",
    "train_hosts, test_hosts = build_train_test(train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_hosts['text'] = train_hosts[\"index\"].apply(text_from_id)\n",
    "# train_hosts[\"class_codes\"] = pd.Categorical(train_hosts[\"class\"]).codes\n",
    "# train_hosts.to_csv(\"train_hosts_UPLOAD_DRIVE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_hosts['text'] = test_hosts[\"index\"].apply(text_from_id)\n",
    "# test_hosts.to_csv(\"test_hosts_UPLOAD_DRIVE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hosts = pd.read_csv(\"train_hosts_UPLOAD_DRIVE.csv\", index_col=0)\n",
    "train_hosts.text = train_hosts.text.apply(literal_eval)\n",
    "\n",
    "test_hosts = pd.read_csv(\"test_hosts_UPLOAD_DRIVE.csv\", index_col=0)\n",
    "test_hosts.text = test_hosts.text.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>class_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9032</td>\n",
       "      <td>health/medical</td>\n",
       "      <td>[   #Polepharma » Flux Polepharma » Flux des c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5346</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>[                            301 Moved Permane...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18778</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>[   (BUTTON) Fermer\\n, \\n,    En poursuivant v...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11939</td>\n",
       "      <td>education/research</td>\n",
       "      <td>[   #HAL\\n, \\n,    (BUTTON) Toggle navigation\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17502</td>\n",
       "      <td>tech/science</td>\n",
       "      <td>[   User-Agent: * Disallow: Disallow: /publish...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index               class  \\\n",
       "0   9032      health/medical   \n",
       "1   5346       entertainment   \n",
       "2  18778       entertainment   \n",
       "3  11939  education/research   \n",
       "4  17502        tech/science   \n",
       "\n",
       "                                                text  class_codes  \n",
       "0  [   #Polepharma » Flux Polepharma » Flux des c...            3  \n",
       "1  [                            301 Moved Permane...            2  \n",
       "2  [   (BUTTON) Fermer\\n, \\n,    En poursuivant v...            2  \n",
       "3  [   #HAL\\n, \\n,    (BUTTON) Toggle navigation\\...            1  \n",
       "4  [   User-Agent: * Disallow: Disallow: /publish...            7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hosts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_fraction = 0\n",
    "end_fraction = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def whole_preprocessing(id, \n",
    "                        start_fraction=start_fraction, \n",
    "                        end_fraction= end_fraction):\n",
    "    \n",
    "    list_text = text_from_id(id)\n",
    "    list_text = process_text(list_text, start_fraction, end_fraction)\n",
    "    text = join_with_SEP(list_text)\n",
    "    series_text = pd.Series([text])\n",
    "    series_text = replace_by_special_token(series_text)\n",
    "    series_text = punctuation_by_space(series_text)\n",
    "    series_text = series_text.apply(remove_stop_words)\n",
    "    series_text = series_text.apply(split_by_SEP)\n",
    "    series_text = series_text.apply(remove_empty_rows)\n",
    "    series_text = series_text.apply(remove_single_characters)\n",
    "    series_text = series_text.apply(lambda x : list(OrderedDict.fromkeys(x)))\n",
    "    \n",
    "    return series_text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hosts[\"text_processed\"] = train_hosts.text.apply(process_text, args=(start_fraction, end_fraction,))\n",
    "train_hosts[\"text_processed\"] = train_hosts.text_processed.apply(join_with_SEP)\n",
    "train_hosts[\"text_processed\"] = replace_by_special_token(train_hosts[\"text_processed\"])\n",
    "train_hosts[\"text_processed\"] = punctuation_by_space(train_hosts[\"text_processed\"])\n",
    "train_hosts[\"text_processed\"] = train_hosts.text_processed.apply(remove_stop_words)\n",
    "train_hosts[\"text_processed\"] = train_hosts.text_processed.apply(split_by_SEP)\n",
    "train_hosts[\"text_processed\"] = train_hosts.text_processed.apply(remove_empty_rows)\n",
    "train_hosts[\"text_processed\"] = train_hosts.text_processed.apply(remove_single_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hosts[\"text_processed_no_single_words\"] = train_hosts.text_processed.apply(remove_single_word_rows)\n",
    "train_hosts[\"text_processed_no_dupl\"] = train_hosts.text_processed.apply(lambda x : list(OrderedDict.fromkeys(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = dict()\n",
    "for cla in train_hosts[\"class\"].unique() :\n",
    "    dico[cla] = Counter(dict())\n",
    "    df = train_hosts[train_hosts[\"class\"] == cla]\n",
    "    for i in range(df.shape[0]) :\n",
    "        dico[cla] += Counter(df.text_processed_no_dupl.iloc[i])\n",
    "    dico[cla] = dict(dico[cla])\n",
    "    dico[cla] = {k: v * df.shape[0]/train_hosts.shape[0] for k, v in dico[cla].items()}\n",
    "    dico[cla] = {k: v for k, v in sorted(dico[cla].items(), reverse=True, key=lambda item: item[1])}\n",
    "\n",
    "counter = Counter({})\n",
    "for cla in train_hosts[\"class\"].unique():\n",
    "    counter+= Counter(dico[cla])\n",
    "counter = {k: v for k, v in sorted(counter.items(), reverse=True, key=lambda item: item[1])}\n",
    "\n",
    "introduced_tokens = [\"date\", \"prix\", \"heure\"]\n",
    "L = [k for k, v in counter.items() if v > 100]\n",
    "for tok in introduced_tokens :\n",
    "    if tok in L :\n",
    "        L.remove(tok)\n",
    "        \n",
    "train_hosts[\"text_processed_2\"] = train_hosts.text_processed_no_dupl.apply(filtering_most_repetitive_rows, args=(L,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hosts[\"text_processed\"] = test_hosts.text.apply(process_text, args=(start_fraction, end_fraction,)) \n",
    "test_hosts[\"text_processed\"] = test_hosts.text_processed.apply(join_with_SEP)\n",
    "test_hosts[\"text_processed\"] = replace_by_special_token(test_hosts[\"text_processed\"])\n",
    "test_hosts[\"text_processed\"] = punctuation_by_space(test_hosts[\"text_processed\"])\n",
    "test_hosts[\"text_processed\"] = test_hosts.text_processed.apply(remove_stop_words)\n",
    "test_hosts[\"text_processed\"] = test_hosts.text_processed.apply(split_by_SEP)\n",
    "test_hosts[\"text_processed\"] = test_hosts.text_processed.apply(remove_empty_rows)\n",
    "test_hosts[\"text_processed\"] = test_hosts.text_processed.apply(remove_single_characters)\n",
    "test_hosts[\"text_processed_no_single_words\"] = test_hosts.text_processed.apply(remove_single_word_rows)\n",
    "test_hosts[\"text_processed_no_dupl\"] = test_hosts.text_processed.apply(lambda x : list(OrderedDict.fromkeys(x)))\n",
    "test_hosts[\"text_processed_2\"] = test_hosts.text_processed_no_dupl.apply(filtering_most_repetitive_rows, args=(L,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>class_codes</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>text_processed_no_single_words</th>\n",
       "      <th>text_processed_no_dupl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9032</td>\n",
       "      <td>health/medical</td>\n",
       "      <td>[   #Polepharma » Flux Polepharma » Flux des c...</td>\n",
       "      <td>3</td>\n",
       "      <td>[polepharma, polepharma, polepharma, organigra...</td>\n",
       "      <td>[chiffres cles, region centre val loire, regio...</td>\n",
       "      <td>[polepharma, organigramme, chiffres cles, rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5346</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>[                            301 Moved Permane...</td>\n",
       "      <td>2</td>\n",
       "      <td>[301 moved permanently, nginx, 301 moved perma...</td>\n",
       "      <td>[301 moved permanently, 301 moved permanently,...</td>\n",
       "      <td>[301 moved permanently, nginx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18778</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>[   (BUTTON) Fermer\\n, \\n,    En poursuivant v...</td>\n",
       "      <td>2</td>\n",
       "      <td>[poursuivant navigation sans modifier parametr...</td>\n",
       "      <td>[poursuivant navigation sans modifier parametr...</td>\n",
       "      <td>[poursuivant navigation sans modifier parametr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11939</td>\n",
       "      <td>education/research</td>\n",
       "      <td>[   #HAL\\n, \\n,    (BUTTON) Toggle navigation\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hal, ccsd, hal, hal, halshs, medihal, liste p...</td>\n",
       "      <td>[liste portails, episciences org, episciences ...</td>\n",
       "      <td>[hal, ccsd, halshs, medihal, liste portails, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17502</td>\n",
       "      <td>tech/science</td>\n",
       "      <td>[   User-Agent: * Disallow: Disallow: /publish...</td>\n",
       "      <td>7</td>\n",
       "      <td>[user agent disallow disallow publishers user ...</td>\n",
       "      <td>[user agent disallow disallow publishers user ...</td>\n",
       "      <td>[user agent disallow disallow publishers user ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index               class  \\\n",
       "0   9032      health/medical   \n",
       "1   5346       entertainment   \n",
       "2  18778       entertainment   \n",
       "3  11939  education/research   \n",
       "4  17502        tech/science   \n",
       "\n",
       "                                                text  class_codes  \\\n",
       "0  [   #Polepharma » Flux Polepharma » Flux des c...            3   \n",
       "1  [                            301 Moved Permane...            2   \n",
       "2  [   (BUTTON) Fermer\\n, \\n,    En poursuivant v...            2   \n",
       "3  [   #HAL\\n, \\n,    (BUTTON) Toggle navigation\\...            1   \n",
       "4  [   User-Agent: * Disallow: Disallow: /publish...            7   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  [polepharma, polepharma, polepharma, organigra...   \n",
       "1  [301 moved permanently, nginx, 301 moved perma...   \n",
       "2  [poursuivant navigation sans modifier parametr...   \n",
       "3  [hal, ccsd, hal, hal, halshs, medihal, liste p...   \n",
       "4  [user agent disallow disallow publishers user ...   \n",
       "\n",
       "                      text_processed_no_single_words  \\\n",
       "0  [chiffres cles, region centre val loire, regio...   \n",
       "1  [301 moved permanently, 301 moved permanently,...   \n",
       "2  [poursuivant navigation sans modifier parametr...   \n",
       "3  [liste portails, episciences org, episciences ...   \n",
       "4  [user agent disallow disallow publishers user ...   \n",
       "\n",
       "                              text_processed_no_dupl  \n",
       "0  [polepharma, organigramme, chiffres cles, rese...  \n",
       "1                     [301 moved permanently, nginx]  \n",
       "2  [poursuivant navigation sans modifier parametr...  \n",
       "3  [hal, ccsd, halshs, medihal, liste portails, a...  \n",
       "4  [user agent disallow disallow publishers user ...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hosts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_hosts.text_processed_no_single_words.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc = dict(np.array(train_hosts[[\"class\",\"class_codes\"]].drop_duplicates()))\n",
    "inv_dicc = {v:k for k, v in dicc.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'health/medical': 3,\n",
       " 'entertainment': 2,\n",
       " 'education/research': 1,\n",
       " 'tech/science': 7,\n",
       " 'politics/government/law': 5,\n",
       " 'news/press': 4,\n",
       " 'sports': 6,\n",
       " 'business/finance': 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data  : local holdout test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_train, local_test = train_test_split(train_hosts, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1495, 4), (499, 4))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_train.shape, local_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "local_train[\"class\"].value_counts().plot(kind='bar');\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def counting_tokens(text):\n",
    "    text = \" \".join(text)\n",
    "    tokens = text.split()\n",
    "    return Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dico = dict()\n",
    "for cla in train_hosts[\"class\"].unique() :\n",
    "    dico[cla] = Counter(dict())\n",
    "    df = local_train[local_train[\"class\"] == cla]\n",
    "    for i in range(df.shape[0]) :\n",
    "        dico[cla] += counting_tokens(df.text_processed_no_single_words.iloc[i])\n",
    "    dico[cla] = dict(dico[cla])\n",
    "    dico[cla] = {k: v for k, v in sorted(dico[cla].items(), reverse=True, key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dico[\"health/medical\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dico[\"education/research\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## sentence frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>class_codes</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>text_processed_no_single_words</th>\n",
       "      <th>text_processed_no_dupl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9032</td>\n",
       "      <td>health/medical</td>\n",
       "      <td>[   #Polepharma » Flux Polepharma » Flux des c...</td>\n",
       "      <td>3</td>\n",
       "      <td>[polepharma, polepharma, polepharma, organigra...</td>\n",
       "      <td>[chiffres cles, region centre val loire, regio...</td>\n",
       "      <td>[polepharma, organigramme, chiffres cles, rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5346</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>[                            301 Moved Permane...</td>\n",
       "      <td>2</td>\n",
       "      <td>[301 moved permanently, nginx, 301 moved perma...</td>\n",
       "      <td>[301 moved permanently, 301 moved permanently,...</td>\n",
       "      <td>[301 moved permanently, nginx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18778</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>[   (BUTTON) Fermer\\n, \\n,    En poursuivant v...</td>\n",
       "      <td>2</td>\n",
       "      <td>[poursuivant navigation sans modifier parametr...</td>\n",
       "      <td>[poursuivant navigation sans modifier parametr...</td>\n",
       "      <td>[poursuivant navigation sans modifier parametr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11939</td>\n",
       "      <td>education/research</td>\n",
       "      <td>[   #HAL\\n, \\n,    (BUTTON) Toggle navigation\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hal, ccsd, hal, hal, halshs, medihal, liste p...</td>\n",
       "      <td>[liste portails, episciences org, episciences ...</td>\n",
       "      <td>[hal, ccsd, halshs, medihal, liste portails, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17502</td>\n",
       "      <td>tech/science</td>\n",
       "      <td>[   User-Agent: * Disallow: Disallow: /publish...</td>\n",
       "      <td>7</td>\n",
       "      <td>[user agent disallow disallow publishers user ...</td>\n",
       "      <td>[user agent disallow disallow publishers user ...</td>\n",
       "      <td>[user agent disallow disallow publishers user ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index               class  \\\n",
       "0   9032      health/medical   \n",
       "1   5346       entertainment   \n",
       "2  18778       entertainment   \n",
       "3  11939  education/research   \n",
       "4  17502        tech/science   \n",
       "\n",
       "                                                text  class_codes  \\\n",
       "0  [   #Polepharma » Flux Polepharma » Flux des c...            3   \n",
       "1  [                            301 Moved Permane...            2   \n",
       "2  [   (BUTTON) Fermer\\n, \\n,    En poursuivant v...            2   \n",
       "3  [   #HAL\\n, \\n,    (BUTTON) Toggle navigation\\...            1   \n",
       "4  [   User-Agent: * Disallow: Disallow: /publish...            7   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  [polepharma, polepharma, polepharma, organigra...   \n",
       "1  [301 moved permanently, nginx, 301 moved perma...   \n",
       "2  [poursuivant navigation sans modifier parametr...   \n",
       "3  [hal, ccsd, hal, hal, halshs, medihal, liste p...   \n",
       "4  [user agent disallow disallow publishers user ...   \n",
       "\n",
       "                      text_processed_no_single_words  \\\n",
       "0  [chiffres cles, region centre val loire, regio...   \n",
       "1  [301 moved permanently, 301 moved permanently,...   \n",
       "2  [poursuivant navigation sans modifier parametr...   \n",
       "3  [liste portails, episciences org, episciences ...   \n",
       "4  [user agent disallow disallow publishers user ...   \n",
       "\n",
       "                              text_processed_no_dupl  \n",
       "0  [polepharma, organigramme, chiffres cles, rese...  \n",
       "1                     [301 moved permanently, nginx]  \n",
       "2  [poursuivant navigation sans modifier parametr...  \n",
       "3  [hal, ccsd, halshs, medihal, liste portails, a...  \n",
       "4  [user agent disallow disallow publishers user ...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hosts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dico = dict()\n",
    "for cla in train_hosts[\"class\"].unique() :\n",
    "    dico[cla] = Counter(dict())\n",
    "    df = train_hosts[train_hosts[\"class\"] == cla]\n",
    "    for i in range(df.shape[0]) :\n",
    "        dico[cla] += Counter(df.text_processed_no_dupl.iloc[i])\n",
    "#     dico[cla] = dict(dico[cla])\n",
    "    dico[cla] = {k: v * df.shape[0]/train_hosts.shape[0] for k, v in dico[cla].items()}\n",
    "    dico[cla] = {k: v for k, v in sorted(dico[cla].items(), reverse=True, key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This way we unveil the sentences that are common to all websites and that we can discard focusing only on the content of each website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "counter = Counter({})\n",
    "for cla in train_hosts[\"class\"].unique():\n",
    "    counter+= Counter(dico[cla])\n",
    "counter = {k: v for k, v in sorted(counter.items(), reverse=True, key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "introduced_tokens = [\"date\", \"prix\", \"heure\"]\n",
    "L = [k for k, v in counter.items() if v > 10]\n",
    "for tok in introduced_tokens :\n",
    "    if tok in L :\n",
    "        L.remove(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_hosts[\"text_processed_2\"] = train_hosts.text_processed_no_dupl.apply(filtering_most_repetitive_rows, args=(L,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train_hosts[\"text_processed_2\"].iloc[50]\n",
    "# train_hosts.iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train_hosts[\"text_processed\"].iloc[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperlinks analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes :  28002\n",
      "Number of edges :  319498\n"
     ]
    }
   ],
   "source": [
    "g = build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sub = nx.subgraph(g, train_hosts[\"index\"].astype(str).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5067"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_sub.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {}\n",
    "classes = train_hosts[\"class\"].unique()\n",
    "for cla in classes :\n",
    "    nodes = train_hosts[train_hosts[\"class\"] == cla][\"index\"].astype(str).to_list()\n",
    "    sum_ = 0\n",
    "    for node in nodes :\n",
    "        sum_+=sum(1 for _ in g.neighbors(node))\n",
    "    dico[cla] = sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>health/medical</th>\n",
       "      <td>1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>10949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education/research</th>\n",
       "      <td>4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech/science</th>\n",
       "      <td>4162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics/government/law</th>\n",
       "      <td>7684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news/press</th>\n",
       "      <td>3686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sports</th>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business/finance</th>\n",
       "      <td>8233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         number of edges\n",
       "health/medical                      1134\n",
       "entertainment                      10949\n",
       "education/research                  4325\n",
       "tech/science                        4162\n",
       "politics/government/law             7684\n",
       "news/press                          3686\n",
       "sports                               280\n",
       "business/finance                    8233"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(dico, orient=\"index\",columns=[\"number of edges\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "edge_list = pd.read_table(\"./data/edgelist.txt\", delimiter=\" \", header=None).rename(columns={0:\"start_node\",\n",
    "                                                                                             1:\"dest_node\",\n",
    "                                                                                             2:\"weight\"})\n",
    "\n",
    "dicc = dict(np.array(train_hosts[[\"class\",\"class_codes\"]].drop_duplicates()))\n",
    "inv_dicc = {v:k for k, v in dicc.items()}\n",
    "\n",
    "def class_index_train(id) :\n",
    "    return train_hosts[train_hosts[\"index\"] == id][\"class\"].iloc[0]\n",
    "\n",
    "edge_list_train = edge_list[edge_list.dest_node.isin(local_train[\"index\"].to_list())]\n",
    "edge_list_train[\"class_dest_node\"] = edge_list_train.dest_node.apply(class_index_train)\n",
    "edge_list_train[\"class_codes\"] = edge_list_train.class_dest_node.map(dicc)\n",
    "\n",
    "def build_edge_proba_vector(column) :\n",
    "    vector = np.zeros(8)\n",
    "    vector[column] = 1\n",
    "    return vector\n",
    "def to_proba_vector(vec):\n",
    "    vec = np.sum(vec)\n",
    "    return vec / np.sum(vec)\n",
    "edge_list_train[\"vector_probas_edge\"] = edge_list_train.class_codes.apply(build_edge_proba_vector) * edge_list_train.weight\n",
    "dico_vector_probas_start_nodes = edge_list_train.groupby('start_node')['vector_probas_edge'].apply(to_proba_vector).to_dict()\n",
    "edge_list_train[\"vector_probas_edge\"] = edge_list_train.start_node.map(dico_vector_probas_start_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The follow up in in 7.3 Approach 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "edge_list_train[edge_list_train.class_codes == 6].weight.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_node</th>\n",
       "      <th>dest_node</th>\n",
       "      <th>weight</th>\n",
       "      <th>class_dest_node</th>\n",
       "      <th>class_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16687</td>\n",
       "      <td>5920</td>\n",
       "      <td>1</td>\n",
       "      <td>health/medical</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19805</td>\n",
       "      <td>18954</td>\n",
       "      <td>4</td>\n",
       "      <td>health/medical</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>19805</td>\n",
       "      <td>12807</td>\n",
       "      <td>1</td>\n",
       "      <td>health/medical</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4694</td>\n",
       "      <td>2651</td>\n",
       "      <td>3</td>\n",
       "      <td>news/press</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4694</td>\n",
       "      <td>19658</td>\n",
       "      <td>1</td>\n",
       "      <td>business/finance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319479</th>\n",
       "      <td>10964</td>\n",
       "      <td>26227</td>\n",
       "      <td>1</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319483</th>\n",
       "      <td>10964</td>\n",
       "      <td>7179</td>\n",
       "      <td>1</td>\n",
       "      <td>tech/science</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319492</th>\n",
       "      <td>19774</td>\n",
       "      <td>16540</td>\n",
       "      <td>1</td>\n",
       "      <td>politics/government/law</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319494</th>\n",
       "      <td>19774</td>\n",
       "      <td>6854</td>\n",
       "      <td>2</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319495</th>\n",
       "      <td>19774</td>\n",
       "      <td>27619</td>\n",
       "      <td>1</td>\n",
       "      <td>politics/government/law</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35167 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        start_node  dest_node  weight          class_dest_node  class_codes\n",
       "25           16687       5920       1           health/medical            3\n",
       "29           19805      18954       4           health/medical            3\n",
       "31           19805      12807       1           health/medical            3\n",
       "39            4694       2651       3               news/press            4\n",
       "44            4694      19658       1         business/finance            0\n",
       "...            ...        ...     ...                      ...          ...\n",
       "319479       10964      26227       1            entertainment            2\n",
       "319483       10964       7179       1             tech/science            7\n",
       "319492       19774      16540       1  politics/government/law            5\n",
       "319494       19774       6854       2            entertainment            2\n",
       "319495       19774      27619       1  politics/government/law            5\n",
       "\n",
       "[35167 rows x 5 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Pure\" nodes to include in training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "edge_list = pd.read_table(\"./data/edgelist.txt\", delimiter=\" \", header=None).rename(columns={0:\"start_node\",\n",
    "                                                                                             1:\"dest_node\",\n",
    "                                                                                             2:\"weight\"})\n",
    "\n",
    "dicc = dict(np.array(train_hosts[[\"class\",\"class_codes\"]].drop_duplicates()))\n",
    "inv_dicc = {v:k for k, v in dicc.items()}\n",
    "\n",
    "def class_index_train(id) :\n",
    "    return train_hosts[train_hosts[\"index\"] == id][\"class\"].iloc[0]\n",
    "\n",
    "edge_list_train = edge_list[edge_list.dest_node.isin(train_hosts[\"index\"].to_list())]\n",
    "edge_list_train[\"class_dest_node\"] = edge_list_train.dest_node.apply(class_index_train)\n",
    "edge_list_train[\"class_codes\"] = edge_list_train.class_dest_node.map(dicc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_num_classes_pointing_at = edge_list_train.groupby(\"start_node\").agg({\"class_codes\":\"nunique\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_nodes = count_num_classes_pointing_at[count_num_classes_pointing_at.class_codes == 1].start_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 100\n",
    "\n",
    "strong_pure_nodes = edge_list_train[(edge_list_train.start_node.isin(pure_nodes))\n",
    "                                    & \n",
    "                                    (edge_list_train.weight >= threshold)\n",
    "                                   ].start_node\n",
    "strong_pure_nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nodes_concerned = edge_list[edge_list.dest_node.isin(test_hosts[\"index\"]) & edge_list.start_node.isin(strong_pure_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_nodes_concerned.groupby(\"dest_node\").agg({\"start_node\":\"nunique\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_node</th>\n",
       "      <th>dest_node</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176432</th>\n",
       "      <td>24002</td>\n",
       "      <td>23497</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214677</th>\n",
       "      <td>20328</td>\n",
       "      <td>24838</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214698</th>\n",
       "      <td>20328</td>\n",
       "      <td>7360</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246395</th>\n",
       "      <td>25158</td>\n",
       "      <td>11923</td>\n",
       "      <td>4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246433</th>\n",
       "      <td>25158</td>\n",
       "      <td>27129</td>\n",
       "      <td>12388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246504</th>\n",
       "      <td>25158</td>\n",
       "      <td>18884</td>\n",
       "      <td>1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246516</th>\n",
       "      <td>25158</td>\n",
       "      <td>26342</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250806</th>\n",
       "      <td>5348</td>\n",
       "      <td>9508</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250914</th>\n",
       "      <td>5348</td>\n",
       "      <td>22854</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256301</th>\n",
       "      <td>26002</td>\n",
       "      <td>5484</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269630</th>\n",
       "      <td>2193</td>\n",
       "      <td>150</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314487</th>\n",
       "      <td>8319</td>\n",
       "      <td>11245</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314509</th>\n",
       "      <td>8319</td>\n",
       "      <td>24572</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314549</th>\n",
       "      <td>8319</td>\n",
       "      <td>22759</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start_node  dest_node  weight\n",
       "176432       24002      23497     799\n",
       "214677       20328      24838     813\n",
       "214698       20328       7360     846\n",
       "246395       25158      11923    4410\n",
       "246433       25158      27129   12388\n",
       "246504       25158      18884    1611\n",
       "246516       25158      26342     141\n",
       "250806        5348       9508      99\n",
       "250914        5348      22854     146\n",
       "256301       26002       5484     208\n",
       "269630        2193        150     830\n",
       "314487        8319      11245      69\n",
       "314509        8319      24572      69\n",
       "314549        8319      22759      69"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nodes_concerned[(test_nodes_concerned.dest_node.isin(df[df.start_node == 1].dest_node.tolist()))\n",
    "                     &\n",
    "                    (test_nodes_concerned.weight >= threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_node</th>\n",
       "      <th>dest_node</th>\n",
       "      <th>weight</th>\n",
       "      <th>class_dest_node</th>\n",
       "      <th>class_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176435</th>\n",
       "      <td>24002</td>\n",
       "      <td>15909</td>\n",
       "      <td>943</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start_node  dest_node  weight class_dest_node  class_codes\n",
       "176435       24002      15909     943   entertainment            2"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list_train[edge_list_train[\"start_node\"] == 24002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text_from_id(23497)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_preditions = pd.read_csv(\"./outputs/wrap_up_18_HK_Approach3_rawtext.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business/finance</th>\n",
       "      <th>education/research</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>health/medical</th>\n",
       "      <th>news/press</th>\n",
       "      <th>politics/government/law</th>\n",
       "      <th>sports</th>\n",
       "      <th>tech/science</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Host</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23497</th>\n",
       "      <td>0.506097</td>\n",
       "      <td>0.020354</td>\n",
       "      <td>0.134616</td>\n",
       "      <td>0.102069</td>\n",
       "      <td>0.105705</td>\n",
       "      <td>0.087882</td>\n",
       "      <td>0.009911</td>\n",
       "      <td>0.033367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       business/finance  education/research  entertainment  health/medical  \\\n",
       "Host                                                                         \n",
       "23497          0.506097            0.020354       0.134616        0.102069   \n",
       "\n",
       "       news/press  politics/government/law    sports  tech/science  \n",
       "Host                                                                \n",
       "23497    0.105705                 0.087882  0.009911      0.033367  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_preditions[best_preditions.index == 23497]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business/finance</th>\n",
       "      <th>education/research</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>health/medical</th>\n",
       "      <th>news/press</th>\n",
       "      <th>politics/government/law</th>\n",
       "      <th>sports</th>\n",
       "      <th>tech/science</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Host</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20285</th>\n",
       "      <td>0.026167</td>\n",
       "      <td>0.102075</td>\n",
       "      <td>0.171752</td>\n",
       "      <td>0.028711</td>\n",
       "      <td>0.010182</td>\n",
       "      <td>0.015321</td>\n",
       "      <td>0.632031</td>\n",
       "      <td>0.013761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20664</th>\n",
       "      <td>0.047387</td>\n",
       "      <td>0.019329</td>\n",
       "      <td>0.255755</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.011598</td>\n",
       "      <td>0.636182</td>\n",
       "      <td>0.005196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <td>0.104704</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.081903</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.247496</td>\n",
       "      <td>0.018042</td>\n",
       "      <td>0.515601</td>\n",
       "      <td>0.016926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13268</th>\n",
       "      <td>0.034335</td>\n",
       "      <td>0.004452</td>\n",
       "      <td>0.069178</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.063651</td>\n",
       "      <td>0.010375</td>\n",
       "      <td>0.805130</td>\n",
       "      <td>0.008390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14518</th>\n",
       "      <td>0.142799</td>\n",
       "      <td>0.007709</td>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.039425</td>\n",
       "      <td>0.009846</td>\n",
       "      <td>0.021130</td>\n",
       "      <td>0.707521</td>\n",
       "      <td>0.004102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16695</th>\n",
       "      <td>0.029953</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.052306</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>0.045222</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.851909</td>\n",
       "      <td>0.002360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19734</th>\n",
       "      <td>0.092735</td>\n",
       "      <td>0.010064</td>\n",
       "      <td>0.098548</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.041989</td>\n",
       "      <td>0.010889</td>\n",
       "      <td>0.713449</td>\n",
       "      <td>0.023828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>0.044236</td>\n",
       "      <td>0.072294</td>\n",
       "      <td>0.218519</td>\n",
       "      <td>0.046894</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>0.014651</td>\n",
       "      <td>0.567026</td>\n",
       "      <td>0.031871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607</th>\n",
       "      <td>0.030033</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.065561</td>\n",
       "      <td>0.011576</td>\n",
       "      <td>0.038216</td>\n",
       "      <td>0.007992</td>\n",
       "      <td>0.832408</td>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       business/finance  education/research  entertainment  health/medical  \\\n",
       "Host                                                                         \n",
       "20285          0.026167            0.102075       0.171752        0.028711   \n",
       "20664          0.047387            0.019329       0.255755        0.019967   \n",
       "6688           0.104704            0.004178       0.081903        0.011152   \n",
       "13268          0.034335            0.004452       0.069178        0.004489   \n",
       "14518          0.142799            0.007709       0.067467        0.039425   \n",
       "16695          0.029953            0.001702       0.052306        0.007494   \n",
       "19734          0.092735            0.010064       0.098548        0.008498   \n",
       "1949           0.044236            0.072294       0.218519        0.046894   \n",
       "14607          0.030033            0.006209       0.065561        0.011576   \n",
       "\n",
       "       news/press  politics/government/law    sports  tech/science  \n",
       "Host                                                                \n",
       "20285    0.010182                 0.015321  0.632031      0.013761  \n",
       "20664    0.004586                 0.011598  0.636182      0.005196  \n",
       "6688     0.247496                 0.018042  0.515601      0.016926  \n",
       "13268    0.063651                 0.010375  0.805130      0.008390  \n",
       "14518    0.009846                 0.021130  0.707521      0.004102  \n",
       "16695    0.045222                 0.009056  0.851909      0.002360  \n",
       "19734    0.041989                 0.010889  0.713449      0.023828  \n",
       "1949     0.004509                 0.014651  0.567026      0.031871  \n",
       "14607    0.038216                 0.007992  0.832408      0.008006  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_preditions.iloc[np.where(np.array(best_preditions).argmax(axis=1) == 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text_from_id(6688) #news ou sport ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Check vocabulary coverage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import fr_core_news_md\n",
    "nlp = fr_core_news_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# word1 = nlp(\"Voiture\")\n",
    "# word2 = nlp(\"voiture\")\n",
    "# (word1.vector == word2.vector).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import operator \n",
    "\n",
    "def build_vocab(texts):\n",
    "    texts = texts.apply(lambda x: \" \".join(x))\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab\n",
    "def check_coverage(vocab, embeddings_index):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    nb_known_words = 0\n",
    "    nb_unknown_words = 0\n",
    "    for word in vocab.keys():\n",
    "        if embeddings_index[word] in nlp.vocab :\n",
    "            known_words[word] = embeddings_index[word]\n",
    "            nb_known_words += vocab[word]\n",
    "        else :\n",
    "            unknown_words[word] = vocab[word]\n",
    "            nb_unknown_words += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(known_words) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n",
    "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return known_words, unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 34.63% of vocab\n",
      "Found embeddings for  84.29% of all text\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(local_train.text_processed_no_dupl)\n",
    "known_words, unknown_words = check_coverage(vocab, nlp.vocab.strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('authorid', 3475),\n",
       " ('decouvrez', 1153),\n",
       " ('clinicaltrials', 911),\n",
       " ('ndeg', 883),\n",
       " ('0007935', 590),\n",
       " ('0094799', 590),\n",
       " ('confidentialite', 584),\n",
       " ('efficacite', 537),\n",
       " ('daten', 505),\n",
       " ('foliateam', 446),\n",
       " ('codepostal', 432),\n",
       " ('mobilite', 430),\n",
       " ('konnen', 397),\n",
       " ('cci', 397),\n",
       " ('3984375', 389),\n",
       " ('0730099', 389),\n",
       " ('9877910', 382),\n",
       " ('6703868', 382),\n",
       " ('3881816', 365),\n",
       " ('3507812', 365)]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198498"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying CamemBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate SVD reducted tfidf with approach 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried : \n",
    "- tfidf + SVD concatenated with BERT then fit ==> local score : 1.195 |LB score : 1.032\n",
    "- tfidf + SVD concatenated with BERT then SVD again then fit ==> local score : 1.195\n",
    "- tfidf concatenated with BERT then SVD then fit ==> local score 1.198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_local_train = np.load(\"./intermediate_data/local_train_text_non_processed_BERT.npy\")\n",
    "BERT_local_test = np.load(\"./intermediate_data/local_test_text_non_processed_BERT.npy\")\n",
    "\n",
    "target_local_train = np.load(\"./intermediate_data/target_train_text_non_processed_BERT.npy\")\n",
    "target_local_test = np.load(\"./intermediate_data/target_local_test_text_non_processed_BERT.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tfidf ...\n",
      "Building tfidf : Finished\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorize_fit, X_train, X_test = build_tf_idf(train_data_corpus=local_train.text, \n",
    "                                                    min_term_frequency=10, \n",
    "                                                    max_term_frequency=5000, \n",
    "                                                    to_transform=local_test.text, \n",
    "                                                    tfidf_vectorize_fit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(X_train)\n",
    "X_test_pd_svd = svd_model.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.3894954943731375}\n",
      "mean cv on the local train  :  -1.218003589446296\n"
     ]
    }
   ],
   "source": [
    "grid={\"C\":np.logspace(-1,3,15)}\n",
    "\n",
    "logreg_cv = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(BERT_local_train[:, :2],\n",
    "                                                                            target_local_train).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "logreg_cv = GridSearchCV(logreg_cv,grid,cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "logreg_cv.fit(np.concatenate((BERT_local_train, X_train_pd_svd), axis=1), target_local_train)\n",
    "\n",
    "print(logreg_cv.best_params_)\n",
    "print('mean cv on the local train  : ', logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1955181483928206"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score_3(logreg_cv.predict_proba(np.concatenate((BERT_local_test, X_test_pd_svd), axis=1)), target_local_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When i fit the tfidf on the whole training the mean cv on the training is not good, so i only train it on the local and app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tfidf ...\n",
      "Building tfidf : Finished\n"
     ]
    }
   ],
   "source": [
    "# tfidf_vectorize_fit, X_train, X_test = build_tf_idf(train_data_corpus=train_hosts.text, \n",
    "#                                                     min_term_frequency=10, \n",
    "#                                                     max_term_frequency=5000, \n",
    "#                                                     to_transform=test_hosts.text, \n",
    "#                                                     tfidf_vectorize_fit=None)\n",
    "tfidf_vectorize_fit, X_train, X_test = build_tf_idf(train_data_corpus=local_train.text, \n",
    "                                                    min_term_frequency=10, \n",
    "                                                    max_term_frequency=5000, \n",
    "                                                    to_transform=local_test.text, \n",
    "                                                    tfidf_vectorize_fit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(np.concatenate((X_train.todense(), X_test.todense())))\n",
    "X_test_pd_svd = svd_model.transform(tfidf_vectorize_fit.transform(test_hosts.text.str.join(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_train = np.concatenate((BERT_local_train, BERT_local_test))\n",
    "target_BERT_train = np.concatenate((target_local_train, target_local_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.3894954943731375}\n",
      "mean cv on the train  :  -1.1955158274103017\n"
     ]
    }
   ],
   "source": [
    "grid={\"C\":np.logspace(-1,3,15)}\n",
    "\n",
    "logreg_cv = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(BERT_local_train[:, :2],\n",
    "                                                                            target_local_train).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "logreg_cv = GridSearchCV(logreg_cv,grid,cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "logreg_cv.fit(np.concatenate((BERT_train, X_train_pd_svd), axis=1), target_BERT_train)\n",
    "\n",
    "print(logreg_cv.best_params_)\n",
    "print('mean cv on the train  : ', logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_test = np.load(\"./intermediate_data/BERT_test_text_non_processed_76_133_289_304_349_437_525.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logreg_cv.predict_proba(np.concatenate((BERT_test, X_test_pd_svd), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(\"./outputs//wrap_up_19_HK_Approach3_rawtext_concat_tfidfSVD_tfidf_fit_on_local_train.csv\", \n",
    "                 list(test_hosts[\"index\"]), \n",
    "                 model_classes_list=list(np.array(train_hosts[[\"class\",\"class_codes\"]].drop_duplicates().sort_values(by='class_codes'))[:,0]), \n",
    "                 predicted_probas=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 268.26957952797244}\n",
      "mean cv on the local train  :  -1.222120948786874\n"
     ]
    }
   ],
   "source": [
    "grid={\"C\":np.logspace(-1,3,15)}\n",
    "\n",
    "svm = SVC(gamma='auto', probability=True, degree=4)\n",
    "\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(BERT_local_train[:, :2],\n",
    "                                                                            target_local_train).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "svm = GridSearchCV(svm,grid,cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "svm.fit(np.concatenate((BERT_local_train, X_train_pd_svd), axis=1), target_local_train)\n",
    "\n",
    "print(svm.best_params_)\n",
    "print('mean cv on the local train  : ', svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.200742461981602"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score_3(svm.predict_proba(np.concatenate((BERT_local_test, X_test_pd_svd), axis=1)), target_local_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SVD reducted concatenated matrix from 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "svd_model_2 = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_svd2_concat_BERTSVD1 = svd_model_2.fit_transform(np.concatenate((BERT_local_train, X_train_pd_svd), axis=1))\n",
    "X_test_svd2_concat_BERTSVD1 = svd_model_2.transform(np.concatenate((BERT_local_test, X_test_pd_svd), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   57.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.3894954943731375}\n",
      "mean cv on the local train  :  -1.2155598321955772\n"
     ]
    }
   ],
   "source": [
    "grid={\"C\":np.logspace(-1,3,15)}\n",
    "\n",
    "logreg_cv = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(BERT_local_train[:, :2],\n",
    "                                                                            target_local_train).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "logreg_cv = GridSearchCV(logreg_cv,grid,cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "logreg_cv.fit(X_train_svd2_concat_BERTSVD1, target_local_train)\n",
    "\n",
    "print(logreg_cv.best_params_)\n",
    "print('mean cv on the local train  : ', logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1950012026136316"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score_3(logreg_cv.predict_proba(X_test_svd2_concat_BERTSVD1), target_local_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 268.26957952797244}\n",
      "mean cv on the local train  :  -1.2218369376124707\n"
     ]
    }
   ],
   "source": [
    "grid={\"C\":np.logspace(-1,3,15)}\n",
    "\n",
    "svm = SVC(gamma='auto', probability=True, degree=4)\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(BERT_local_train[:, :2],\n",
    "                                                                            target_local_train).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "svm = GridSearchCV(svm,grid,cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "svm.fit(X_train_svd2_concat_BERTSVD1, target_local_train)\n",
    "\n",
    "print(svm.best_params_)\n",
    "print('mean cv on the local train  : ', svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.198673035908849"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score_3(svm.predict_proba(X_test_svd2_concat_BERTSVD1), target_local_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Concatenate just ater tfidf then apply SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "svd_model_3 = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_svd3 = svd_model_3.fit_transform(np.concatenate((BERT_local_train, X_train.todense()),axis=1))\n",
    "X_test_svd3 = svd_model_3.transform(np.concatenate((BERT_local_test, X_test.todense()),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   54.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.3894954943731375}\n",
      "mean cv on the local train  :  -1.21155912529368\n"
     ]
    }
   ],
   "source": [
    "grid={\"C\":np.logspace(-1,3,15)}\n",
    "\n",
    "logreg_cv = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(BERT_local_train[:, :2],\n",
    "                                                                            target_local_train).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "logreg_cv = GridSearchCV(logreg_cv,grid,cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "logreg_cv.fit(X_train_svd3, target_local_train)\n",
    "\n",
    "print(logreg_cv.best_params_)\n",
    "print('mean cv on the local train  : ', logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1980122939017102"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score_3(logreg_cv.predict_proba(X_test_svd3), target_local_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Approach 3 with SVM \n",
    "\n",
    "very slight improvement with svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "BERT_local_train = np.load(\"./intermediate_data/local_train_text_non_processed_BERT.npy\")\n",
    "BERT_local_test = np.load(\"./intermediate_data/local_test_text_non_processed_BERT.npy\")\n",
    "\n",
    "target_local_train = np.load(\"./intermediate_data/target_train_text_non_processed_BERT.npy\")\n",
    "target_local_test = np.load(\"./intermediate_data/target_local_test_text_non_processed_BERT.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 517.9474679231207}\n",
      "mean cv on the local train  :  -1.2263000850270733\n"
     ]
    }
   ],
   "source": [
    "grid={\"C\":np.logspace(-1,3,15)}\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "svm = SVC(gamma='auto', probability=True, degree=4)\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(BERT_local_train[:, :2],\n",
    "                                                                            target_local_train).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "svm = GridSearchCV(svm,grid,cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "svm.fit(BERT_local_train, target_local_train)\n",
    "\n",
    "print(svm.best_params_)\n",
    "print('mean cv on the local train  : ', svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2121876868407406"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score_3(svm.predict_proba(BERT_local_test), target_local_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2.6826957952797246}\n",
      "mean cv on the local train  :  -1.2258617863257344\n"
     ]
    }
   ],
   "source": [
    "grid={\"C\":np.logspace(-1,3,15)}\n",
    "\n",
    "logreg_cv = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(BERT_local_train[:, :2],\n",
    "                                                                            target_local_train).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "logreg_cv = GridSearchCV(logreg_cv,grid,cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "logreg_cv.fit(BERT_local_train, target_local_train)\n",
    "\n",
    "print(logreg_cv.best_params_)\n",
    "print('mean cv on the local train  : ', logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2166314602075938"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score_3(logreg_cv.predict_proba(BERT_local_test), target_local_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as approach 2 but we average the CLS tokens embedding we get after the subdivision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried this both on the : \n",
    "- `text_processed_no_single_words` column : local score 1.26 => LB score 1.11\n",
    "- `text_processed_no_dupl` column : local score 1.28 => LB score 1.08\n",
    "- `text` (no precessing ) : local score 1.21 => LB score 1.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN = train_hosts.shape[0]\n",
    "for j in range(train_hosts.shape[0]):\n",
    "    sys.stdout.write('\\r'+str(j)+\"/\"+str(LEN))\n",
    "    cla = train_hosts[\"class_codes\"].iloc[j]\n",
    "\n",
    "    txt = \". \".join(train_hosts.text_processed_no_dupl.iloc[j])\n",
    "    try :\n",
    "      tokens = tokenizer_.encode(txt, add_special_tokens=True)\n",
    "      SHAPE = len(tokens[1:-1])\n",
    "      new_tokens = []\n",
    "      for i in range(int(SHAPE/510)+1):\n",
    "          min_ = min((i+1)*510,SHAPE)\n",
    "          if min_ == SHAPE :\n",
    "              L = [tokenizer_.cls_token_id] + tokens[i*510:min_] + [tokenizer_.eos_token_id]\n",
    "              new_tokens.append(L + [tokenizer_.pad_token_id]*(512 - len(L)))\n",
    "          else :\n",
    "              new_tokens.append([tokenizer_.cls_token_id] + tokens[i*510:min_] + [tokenizer_.eos_token_id] )\n",
    "      # new_tokens = new_tokens[:350]\n",
    "      with torch.no_grad() :\n",
    "          new_train_ = model(torch.tensor(new_tokens).cuda())[0][:,0,:]\n",
    "      del new_tokens\n",
    "      torch.cuda.empty_cache()\n",
    "      if j == 0 :\n",
    "        new_train = new_train_.detach().cpu().numpy().mean(axis=0).reshape(1,-1)\n",
    "        new_train_target = [cla]\n",
    "      else :\n",
    "        new_train = np.concatenate((new_train, \n",
    "                                    new_train_.detach().cpu().numpy().mean(axis=0).reshape(1,-1)), \n",
    "                                   axis=0)\n",
    "        new_train_target.append(cla)\n",
    "    except :\n",
    "      new_train = np.concatenate((new_train, np.zeros((1,768))), axis=0)\n",
    "      new_train_target.extend([cla])\n",
    "new_train = np.array(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- join the rows of each text ==> BIG BIG context\n",
    "- Tokenize it \n",
    "- Camembert cannot process suequences longer than 512 tokens => subdivide it\n",
    "    - example : (sequence of 1000 tokens, label_1) =>  [(sequence of 512 tokens, label_1), (sequence of 498 tokens, label_1)]\n",
    "    - We perform a sort of data augmentation here \n",
    "- take the embedding of the CLS tokens\n",
    "- fit a classifier\n",
    "- local score 1.3, LB score : 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "import torch\n",
    "\n",
    "tokenizer_ = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "model = CamembertModel.from_pretrained('camembert-base')\n",
    "model.eval();\n",
    "model.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_train = []\n",
    "new_train_target = []\n",
    "for j in range(local_train.shape[0]):\n",
    "    \n",
    "    cla = local_train[\"class_codes\"].iloc[j]\n",
    "\n",
    "    txt = \". \".join(local_train.text_processed_no_single_words.iloc[j])\n",
    "        \n",
    "    tokens = tokenizer_.encode(txt, add_special_tokens=True)\n",
    "    SHAPE = len(tokens[1:-1])\n",
    "    new_tokens = []\n",
    "    for i in range(int(SHAPE/510)+1):\n",
    "        min_ = min((i+1)*510,SHAPE)\n",
    "        if min_ == SHAPE :\n",
    "            L = [tokenizer_.cls_token_id] + tokens[i*510:min_] + [tokenizer_.eos_token_id]\n",
    "            new_tokens.append(L + [tokenizer_.pad_token_id]*(512 - len(L)))\n",
    "        else :\n",
    "            new_tokens.append([tokenizer_.cls_token_id] + tokens[i*510:min_] + [tokenizer_.eos_token_id] )\n",
    "            \n",
    "    with torch.no_grad() :\n",
    "        new_train = model(torch.tensor(new_tokens).cuda())[0]\n",
    "    del new_tokens\n",
    "    torch.cuda.empty_cache()\n",
    "    new_train = new_train.squeeze(0)[0].detach().cpu().numpy()\n",
    "    new_train_target = [cla]* len(new_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Approach 1 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- take the mean of the CLS token embedding of each row in each text\n",
    "- this will be the representation of the text\n",
    "- local_test score : 1.8 (colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CAMEMBERT_emb = []\n",
    "\n",
    "for i, text in enumerate(local_train.text_processed_no_single_words) :\n",
    "    \n",
    "    input_ids = tokenizer_.batch_encode_plus(text, add_special_tokens=True, return_tensors='pt')[\"input_ids\"].to('cuda')\n",
    "    with torch.no_grad():\n",
    "        CLS_token_last_embeddings = model(input_ids)[0]\n",
    "    del input_ids\n",
    "    torch.cuda.empty_cache()\n",
    "    CLS_token_last_embeddings = CLS_token_last_embeddings.detach().cpu().numpy()\n",
    "    CAMEMBERT_emb.append(CLS_token_last_embeddings[:,0,:].mean(axis=0))\n",
    "    \n",
    "CAMEMBERT_emb = np.array(CAMEMBERT_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto', probability=True)\n",
    "clf.fit(CAMEMBERT_emb, local_train.class_codes.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CAMEMBERT_emb_test = []\n",
    "\n",
    "for i, text in enumerate(local_test.iloc[:1].text_processed_no_single_words) :\n",
    "    input_ids = tokenizer_.batch_encode_plus(text, add_special_tokens=True, return_tensors='pt')[\"input_ids\"].to('cuda')\n",
    "    with torch.no_grad():\n",
    "        CLS_token_last_embeddings = model(input_ids)[0]\n",
    "    del input_ids\n",
    "    torch.cuda.empty_cache()\n",
    "    CLS_token_last_embeddings = CLS_token_last_embeddings.detach().cpu().numpy()\n",
    "    CAMEMBERT_emb_test.append(CLS_token_last_embeddings[:,0,:].mean(axis=0).detach().cpu().numpy())\n",
    "    \n",
    "CAMEMBERT_emb_test = np.array(CAMEMBERT_emb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(CAMEMBERT_emb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "compute_score_3(predictions, local_test.class_codes.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CAMEMBERT_emb = []\n",
    "\n",
    "for i, text in enumerate(train_hosts.text_processed_no_single_words) :\n",
    "    input_ids = tokenizer_.batch_encode_plus(text, add_special_tokens=True, return_tensors='pt')[\"input_ids\"].to('cuda')\n",
    "#     input_ids = tokenizer_.batch_encode_plus(text, add_special_tokens=True, return_tensors='pt')[\"input_ids\"]\n",
    "    with torch.no_grad():\n",
    "        CLS_token_last_embeddings = model(input_ids)[0]\n",
    "    CAMEMBERT_emb.append(CLS_token_last_embeddings[:,0,:].mean(axis=0).detach().cpu().numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "#     CAMEMBERT_emb.append(CLS_token_last_embeddings[:,0,:].mean(axis=0).detach().numpy())\n",
    "CAMEMBERT_emb = np.array(CAMEMBERT_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(gamma='auto', probability=True)\n",
    "clf.fit(CAMEMBERT_emb, train_hosts.class_codes.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CAMEMBERT_emb_test = []\n",
    "\n",
    "for i, text in enumerate(test_hosts.text_processed_no_single_words) :\n",
    "    input_ids = tokenizer_.batch_encode_plus(text, add_special_tokens=True, return_tensors='pt')[\"input_ids\"].to('cuda')\n",
    "    with torch.no_grad():\n",
    "        CLS_token_last_embeddings = model(input_ids)[0]\n",
    "    CAMEMBERT_emb_test.append(CLS_token_last_embeddings[:,0,:].mean(axis=0).detach().cpu().numpy())\n",
    "    \n",
    "CAMEMBERT_emb_test = np.array(CAMEMBERT_emb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(CAMEMBERT_emb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tfidf ...\n",
      "Building tfidf : Finished\n"
     ]
    }
   ],
   "source": [
    "# tfidf_vectorize_fit, X_train, X_test = build_tf_idf(train_data_corpus=local_train.text_processed_no_single_words, \n",
    "#                                                     min_term_frequency=10, \n",
    "#                                                     max_term_frequency=5000, \n",
    "#                                                     to_transform=local_test.text_processed_no_single_words, \n",
    "#                                                     tfidf_vectorize_fit=None)\n",
    "\n",
    "# tfidf_vectorize_fit, X_train, X_test = build_tf_idf(train_data_corpus=local_train.text_processed_no_dupl, \n",
    "#                                                     min_term_frequency=10, \n",
    "#                                                     max_term_frequency=5000, \n",
    "#                                                     to_transform=local_test.text_processed_no_dupl, \n",
    "#                                                     tfidf_vectorize_fit=None)\n",
    "\n",
    "tfidf_vectorize_fit, X_train, X_test = build_tf_idf(train_data_corpus=local_train.text_processed_2, \n",
    "                                                    min_term_frequency=10, \n",
    "                                                    max_term_frequency=5000, \n",
    "                                                    to_transform=local_test.text_processed_2, \n",
    "                                                    tfidf_vectorize_fit=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.386600386002064"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(gamma='auto', probability=True)\n",
    "svm.fit(X_train, local_train.class_codes.values)\n",
    "predictions = svm.predict_proba(X_test)\n",
    "compute_score_3(predictions, local_test.class_codes.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3624899875941183"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "logreg.fit(X_train, local_train.class_codes.values)\n",
    "predictions = logreg.predict_proba(X_test)\n",
    "compute_score_3(predictions, local_test.class_codes.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1 :\n",
    "- Process the texts\n",
    "- fit a tf idf vectorizer\n",
    "- perform SVD on the tf idf matrix\n",
    "- use and SVM no tuned to classify\n",
    "\n",
    "- `text_processed` : local 1.29, LB : 1.13\n",
    "- `text_processed_no_single_words` : \n",
    "- `text_processed_2` : local 1.27- 1.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2881498270833325"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(X_train)\n",
    "X_test_pd_svd = svd_model.transform(X_test)\n",
    "\n",
    "svm = SVC(gamma='auto', probability=True)\n",
    "\n",
    "svm.fit(X_train_pd_svd, local_train.class_codes.values)\n",
    "predictions = svm.predict_proba(X_test_pd_svd)\n",
    "compute_score_3(predictions, local_test.class_codes.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0}\n",
      "Score on the local train cv :  -1.3171443769126219\n"
     ]
    }
   ],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(X_train)\n",
    "X_test_pd_svd = svd_model.transform(X_test)\n",
    "\n",
    "\n",
    "grid={\"C\":np.logspace(-2,1,15)}\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "svm = SVC(gamma='auto', probability=True)\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(X_train_pd_svd[:, :2],\n",
    "                                                                            local_train.class_codes.values).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "svm = GridSearchCV(svm,grid,cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "svm.fit(X_train_pd_svd, local_train.class_codes.values)\n",
    "\n",
    "print(svm.best_params_)\n",
    "print('Score on the local train cv : ', svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2790146951165169"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = svm.best_params_\n",
    "svm_all_train = SVC(gamma='auto', probability=True, C = params[\"C\"])\n",
    "svm_all_train.fit(X_train_pd_svd, local_train.class_codes.values)\n",
    "predictions = svm_all_train.predict_proba(X_test_pd_svd)\n",
    "compute_score_3(predictions, local_test.class_codes.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1495, 500), (499, 500))"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pd_svd.shape, X_test_pd_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_pd_svd, local_train.class_codes.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0}\n",
      "Score on the local train cv :  -1.8157287401582944\n"
     ]
    }
   ],
   "source": [
    "grid={\"C\":np.logspace(-2,1,15)}\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "svm = SVC(gamma='auto', probability=True)\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(X_resampled[:, :2],\n",
    "                                                                            y_resampled).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "svm = GridSearchCV(svm,grid,cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "svm.fit(X_resampled, y_resampled)\n",
    "\n",
    "print(svm.best_params_)\n",
    "print('Score on the local train cv : ', svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6508929263750274"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = svm.best_params_\n",
    "svm_all_train = SVC(gamma='auto', probability=True, C = params[\"C\"])\n",
    "svm_all_train.fit(X_resampled, y_resampled)\n",
    "predictions = svm_all_train.predict_proba(X_test_pd_svd)\n",
    "compute_score_3(predictions, local_test.class_codes.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 5\n",
    "\n",
    "Same as approach 1 but after predicting the probas using the text, we average the vectors with the vec of probas built using the edges and weights for nodes that have a connection\n",
    "\n",
    "local score (using processed_2) : 1.27 ==> LB score : 1.14\n",
    "\n",
    "local score (using no_dupl) : 1. ==> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(X_train)\n",
    "X_test_pd_svd = svd_model.transform(X_test)\n",
    "\n",
    "svm = SVC(gamma='auto', probability=True)\n",
    "svm.fit(X_train_pd_svd, local_train.class_codes.values)\n",
    "predictions = svm.predict_proba(X_test_pd_svd)\n",
    "\n",
    "# logreg = LogisticRegression()\n",
    "# logreg.fit(X_train_pd_svd, local_train.class_codes.values)\n",
    "# predictions = logreg.predict_proba(X_test_pd_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   49.1s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 6.105402296585327}\n",
      "Score on the local train cv :  -1.321542579917035\n"
     ]
    }
   ],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(X_train)\n",
    "X_test_pd_svd = svd_model.transform(X_test)\n",
    "\n",
    "\n",
    "grid={\"C\":np.logspace(-2,1,15)}\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "svm = SVC(gamma='auto', probability=True)\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(X_train_pd_svd[:, :2],\n",
    "                                                                            local_train.class_codes.values).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "svm = GridSearchCV(svm, grid, cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "svm.fit(X_train_pd_svd, local_train.class_codes.values)\n",
    "\n",
    "print(svm.best_params_)\n",
    "print('Score on the local train cv : ', svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "edge_list_test = edge_list[edge_list.dest_node.isin(local_test[\"index\"])]\n",
    "edge_list_test[\"vector_probas_edge_1\"] = edge_list_test.start_node.map(dico_vector_probas_start_nodes)* edge_list_test.weight \n",
    "\n",
    "dico_vector_probas_dest_nodes = edge_list_test.groupby('dest_node')['vector_probas_edge_1'].apply(to_proba_vector).to_dict()\n",
    "edge_list_test[\"vector_probas_edge_1\"] = edge_list_test.dest_node.map(dico_vector_probas_dest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "for p in np.linspace(0,1,11):\n",
    "    new_predictions = []\n",
    "    LEN = local_test.shape[0]\n",
    "    weight_edges_probas = p\n",
    "    weight_text_probas = 1-weight_edges_probas\n",
    "\n",
    "    for i in range(local_test.shape[0]):\n",
    "\n",
    "        node = local_test[\"index\"].iloc[i]\n",
    "        \n",
    "        if (node in edge_list_test.dest_node) :\n",
    "            if dico_vector_probas_dest_nodes[node].shape != () :\n",
    "                new_predictions.append( (dico_vector_probas_dest_nodes[node] * weight_edges_probas \n",
    "                                         + predictions[i] * weight_text_probas)\n",
    "                                        )\n",
    "            else :\n",
    "                new_predictions.append(predictions[i])\n",
    "        else :\n",
    "            new_predictions.append(predictions[i])\n",
    "\n",
    "    new_predictions = np.array(new_predictions)\n",
    "    \n",
    "    scores.append(compute_score_3(np.array(new_predictions), local_test.class_codes.values))\n",
    "plt.xlabel(\"weight given to the edge probas\")\n",
    "plt.plot(np.linspace(0,1,11), scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2734170304436188"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions = []\n",
    "LEN = local_test.shape[0]\n",
    "weight_edges_probas = .2\n",
    "weight_text_probas = 1-weight_edges_probas\n",
    "\n",
    "for i in range(local_test.shape[0]):\n",
    "\n",
    "    node = local_test[\"index\"].iloc[i]\n",
    "\n",
    "    if (node in edge_list_test.dest_node) :\n",
    "        if dico_vector_probas_dest_nodes[node].shape != () :\n",
    "            new_predictions.append( (dico_vector_probas_dest_nodes[node] * weight_edges_probas \n",
    "                                     + predictions[i] * weight_text_probas)\n",
    "                                    )\n",
    "        else :\n",
    "            new_predictions.append(predictions[i])\n",
    "    else :\n",
    "        new_predictions.append(predictions[i])\n",
    "\n",
    "new_predictions = np.array(new_predictions)\n",
    "\n",
    "compute_score_3(np.array(new_predictions), local_test.class_codes.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the approach on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#### READ THE EDGE LIST\n",
    "edge_list = pd.read_table(\"./data/edgelist.txt\", delimiter=\" \", header=None).rename(columns={0:\"start_node\",\n",
    "                                                                                             1:\"dest_node\",\n",
    "                                                                                             2:\"weight\"})\n",
    "\n",
    "#### KEEP THE INFO OF THE NODES WE ARE INTERESTED IN : the nodes in training (testing comes later) \n",
    "#### BECAUSE SOME NODES ARE JUST THERE BUT DO NOT LINK DIRECTLY TO ANY NODE OF OUR TRAIN AND TEST  TEXTS\n",
    "#### For this see the difference of rows between edge_list and edge_list_train\n",
    "edge_list_train = edge_list[edge_list.dest_node.isin(train_hosts[\"index\"].to_list())]\n",
    "\n",
    "\n",
    "#### add class_codes for the nodes of the training\n",
    "def class_index_train(id) :\n",
    "    return train_hosts[train_hosts[\"index\"] == id][\"class\"].iloc[0]\n",
    "edge_list_train[\"class_dest_node\"] = edge_list_train.dest_node.apply(class_index_train)\n",
    "\n",
    "dicc = dict(np.array(train_hosts[[\"class\",\"class_codes\"]].drop_duplicates()))\n",
    "inv_dicc = {v:k for k, v in dicc.items()}\n",
    "\n",
    "edge_list_train[\"class_codes\"] = edge_list_train.class_dest_node.map(dicc)\n",
    "\n",
    "#### The message passing from the labeled nodes to their direct neighbours that point towards them\n",
    "#### We assign to each edge of interest a vector of probabilities over the classes weighted by its graph weight\n",
    "\n",
    "def build_edge_proba_vector(column) :\n",
    "    vector = np.zeros(8)\n",
    "    vector[column] = 1\n",
    "    return vector\n",
    "def to_proba_vector(vec):\n",
    "    vec = np.sum(vec)\n",
    "    return vec / np.sum(vec)\n",
    "\n",
    "edge_list_train[\"vector_probas_edge\"] = edge_list_train.class_codes.apply(build_edge_proba_vector) * edge_list_train.weight\n",
    "dico_vector_probas_start_nodes = edge_list_train.groupby('start_node')['vector_probas_edge'].apply(to_proba_vector).to_dict()\n",
    "edge_list_train[\"vector_probas_edge\"] = edge_list_train.start_node.map(dico_vector_probas_start_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in long_scalars\n",
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "edge_list_test = edge_list[edge_list.dest_node.isin(test_hosts[\"index\"].to_list())]\n",
    "\n",
    "edge_list_test[\"vector_probas_edge_1\"] = edge_list_test.start_node.map(dico_vector_probas_start_nodes) * edge_list_test.weight\n",
    "dico_vector_probas_dest_nodes = edge_list_test.groupby('dest_node')['vector_probas_edge_1'].apply(to_proba_vector).to_dict()\n",
    "edge_list_test[\"vector_probas_edge_1\"] = edge_list_test.dest_node.map(dico_vector_probas_dest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tfidf ...\n",
      "Building tfidf : Finished\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorize_fit, X_train, X_test = build_tf_idf(train_data_corpus=train_hosts.text_processed_2, \n",
    "                                                    min_term_frequency=10, \n",
    "                                                    max_term_frequency=5000, \n",
    "                                                    to_transform=test_hosts.text_processed_2, \n",
    "                                                    tfidf_vectorize_fit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   49.1s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 3.727593720314938}\n",
      "Score on the local train cv :  -1.2852840900049178\n"
     ]
    }
   ],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(X_train)\n",
    "X_test_pd_svd = svd_model.transform(X_test)\n",
    "\n",
    "\n",
    "grid={\"C\":np.logspace(-2,1,15)}\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "svm = SVC(gamma='auto', probability=True)\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(X_train_pd_svd[:, :2],\n",
    "                                                                            train_hosts.class_codes.values).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "svm = GridSearchCV(svm, grid, cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "svm.fit(X_train_pd_svd, train_hosts.class_codes.values)\n",
    "\n",
    "print(svm.best_params_)\n",
    "print('Score on the local train cv : ', svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svm.predict_proba(X_test_pd_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predictions = []\n",
    "LEN = test_hosts.shape[0]\n",
    "\n",
    "weight_edges_probas = .2\n",
    "weight_text_probas = 1-weight_edges_probas\n",
    "\n",
    "\n",
    "for i in range(test_hosts.shape[0]):\n",
    "\n",
    "    node = test_hosts[\"index\"].iloc[i]\n",
    "\n",
    "    if (node in edge_list_test.dest_node) :\n",
    "        if dico_vector_probas_dest_nodes[node].shape != () :\n",
    "            new_predictions.append( (dico_vector_probas_dest_nodes[node] * weight_edges_probas \n",
    "                                     + predictions[i] * weight_text_probas)\n",
    "                                    )\n",
    "        else :\n",
    "            new_predictions.append(predictions[i])\n",
    "    else :\n",
    "        new_predictions.append(predictions[i])\n",
    "\n",
    "new_predictions = np.array(new_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18462681, 0.32387237, 0.18337666, ..., 0.06681725, 0.02363196,\n",
       "        0.15857943],\n",
       "       [0.30136476, 0.04543025, 0.45496872, ..., 0.03829115, 0.03683518,\n",
       "        0.09837716],\n",
       "       [0.3878999 , 0.02368137, 0.45090921, ..., 0.01998476, 0.02419444,\n",
       "        0.03456051],\n",
       "       ...,\n",
       "       [0.30251123, 0.03816379, 0.4978191 , ..., 0.03119177, 0.01453152,\n",
       "        0.08105035],\n",
       "       [0.48513366, 0.03322485, 0.31424417, ..., 0.06052829, 0.01818904,\n",
       "        0.05755059],\n",
       "       [0.0151722 , 0.03120765, 0.01368877, ..., 0.0098126 , 0.00620106,\n",
       "        0.87383819]])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(\"./outputs/wrap_up_15_HK_Approach5_text_processed_2_SVDSVM_crossvalidated_corrected.csv\", \n",
    "                 list(test_hosts[\"index\"]), \n",
    "                 model_classes_list=list(np.array(train_hosts[[\"class\",\"class_codes\"]].drop_duplicates().sort_values(by='class_codes'))[:,0]), \n",
    "                 predicted_probas=new_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Approach 4\n",
    "\n",
    "Augment the training data set by including some non labeled nodes.\n",
    "\n",
    "The conditions to include a node as labeled X are : \n",
    "- The node should point toward a node labeled X in the non augmented training set\n",
    "- The node should point towards nodes that are all labeled X-\n",
    "- the weight of the link starting from that node should be more than `threshold`\n",
    "\n",
    "We eventually add 3503 more rows in the training set if threshold = 0\n",
    "\n",
    "We can still go with the same logic to the next levels of neighbours if we want to.\n",
    "\n",
    "threhold = 0 == > 3503 more rows in training ==> Local score 1.25-1.26 , LB score 1.15-1.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "edge_list_train[[\"start_node\",\"class_dest_node\"]]\n",
    "df = edge_list_train.groupby('start_node').agg({\"class_dest_node\":\"nunique\"})\n",
    "nodes_to_keep = df[df[\"class_dest_node\"] == 1].index\n",
    "nodes_not_to_keep = df[df[\"class_dest_node\"] != 1].index\n",
    "df = edge_list_train[(edge_list_train.start_node.isin(nodes_to_keep)) &\n",
    "                (edge_list_train.weight > threshold)]\n",
    "df.drop_duplicates(subset=[\"start_node\",\"class_dest_node\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "local_train, local_test = train_test_split(train_hosts, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_train = local_train[[\"text_processed_no_dupl\",\n",
    "                         \"class_codes\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "additional_data = pd.concat([df.start_node.apply(whole_preprocessing),\n",
    "                             df.class_dest_node.map(dicc)],\n",
    "                            axis=1).rename(columns= {\"start_node\":\"text_processed_no_dupl\",\n",
    "                                                    \"class_dest_node\":\"class_codes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "additional_data.to_csv(\"additional_data_approach4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_train = pd.concat([new_train, additional_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tfidf ...\n",
      "Building tfidf : Finished\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorize_fit, X_train, X_test = build_tf_idf(train_data_corpus=new_train.text_processed_no_dupl, \n",
    "                                                    min_term_frequency=10, \n",
    "                                                    max_term_frequency=5000, \n",
    "                                                    to_transform=local_test.text_processed_no_dupl, \n",
    "                                                    tfidf_vectorize_fit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2577217856413552"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(X_train)\n",
    "X_test_pd_svd = svd_model.transform(X_test)\n",
    "\n",
    "svm = SVC(gamma='auto', probability=True)\n",
    "\n",
    "svm.fit(X_train_pd_svd, new_train.class_codes.values)\n",
    "predictions = svm.predict_proba(X_test_pd_svd)\n",
    "compute_score_3(predictions, local_test.class_codes.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 14.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.3894954943731375}\n",
      "Score on the local train cv :  -1.3870178905562165\n"
     ]
    }
   ],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(X_train)\n",
    "X_test_pd_svd = svd_model.transform(X_test)\n",
    "\n",
    "\n",
    "grid={\"C\":np.logspace(-2,1,15)}\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "svm = SVC(gamma='auto', probability=True)\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(X_train_pd_svd[:, :2],\n",
    "                                                                            new_train.class_codes.values).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "svm = GridSearchCV(svm, grid, cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "svm.fit(X_train_pd_svd, new_train.class_codes.values)\n",
    "\n",
    "print(svm.best_params_)\n",
    "print('Score on the local train cv : ', svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2556472247598378"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score_3(svm.predict_proba(X_test_pd_svd), local_test.class_codes.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_train = train_hosts[[\"text_processed_no_dupl\",\n",
    "                         \"class_codes\"]]\n",
    "new_train = pd.concat([new_train, additional_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_hosts = pd.read_csv(\"./test_hosts_UPLOAD_DRIVE.csv\", index_col=0)\n",
    "test_hosts.text = test_hosts.text.apply(literal_eval)\n",
    "\n",
    "test_hosts[\"text_processed\"] = test_hosts.text.apply(process_text, args=(start_fraction, end_fraction,)) \n",
    "test_hosts[\"text_processed\"] = test_hosts.text_processed.apply(join_with_SEP)\n",
    "test_hosts[\"text_processed\"] = replace_by_special_token(test_hosts[\"text_processed\"])\n",
    "test_hosts[\"text_processed\"] = punctuation_by_space(test_hosts[\"text_processed\"])\n",
    "test_hosts[\"text_processed\"] = test_hosts.text_processed.apply(remove_stop_words)\n",
    "test_hosts[\"text_processed\"] = test_hosts.text_processed.apply(split_by_SEP)\n",
    "test_hosts[\"text_processed\"] = test_hosts.text_processed.apply(remove_empty_rows)\n",
    "test_hosts[\"text_processed\"] = test_hosts.text_processed.apply(remove_single_characters)\n",
    "# test_hosts[\"text_processed_no_single_words\"] = test_hosts.text_processed.apply(remove_single_word_rows)\n",
    "test_hosts[\"text_processed_no_dupl\"] = test_hosts.text_processed.apply(lambda x : list(OrderedDict.fromkeys(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tfidf ...\n",
      "Building tfidf : Finished\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorize_fit, X_train, X_test = build_tf_idf(train_data_corpus=new_train.text_processed_no_dupl, \n",
    "                                                    min_term_frequency=10, \n",
    "                                                    max_term_frequency=5000, \n",
    "                                                    to_transform=test_hosts.text_processed_no_dupl, \n",
    "                                                    tfidf_vectorize_fit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 16.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0}\n",
      "Score on the local train cv :  -1.3754038084458038\n"
     ]
    }
   ],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(X_train)\n",
    "X_test_pd_svd = svd_model.transform(X_test)\n",
    "\n",
    "\n",
    "grid={\"C\":np.logspace(-2,1,15)}\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "svm = SVC(gamma='auto', probability=True)\n",
    "\n",
    "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(X_train_pd_svd[:, :2],\n",
    "                                                                            new_train.class_codes.values).classes_\n",
    "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
    "\n",
    "svm = GridSearchCV(svm, grid, cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
    "\n",
    "\n",
    "svm.fit(X_train_pd_svd, new_train.class_codes.values)\n",
    "\n",
    "print(svm.best_params_)\n",
    "print('Score on the local train cv : ', svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions = svm.predict_proba(X_test_pd_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "write_submission(\"./outputs/wrap_up_12_HK_Approach4_text_processed_no_dupl_SVDSVM_defaultSVM.csv\", \n",
    "                 list(test_hosts[\"index\"]), \n",
    "                 model_classes_list=list(np.array(train_hosts[[\"class\",\"class_codes\"]].drop_duplicates().sort_values(by='class_codes'))[:,0]), \n",
    "                 predicted_probas=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Approach 3 : \n",
    "\n",
    "- fit the model with approach 1 (or any other model )\n",
    "- for the prediction phase :\n",
    "    - for a given node in the testing set :\n",
    "        - predict the probas of the node\n",
    "        - use the neighbours :\n",
    "            - predict the probas of all its neighbours that have a link weight of more than `threshold` (if there are any)\n",
    "           \n",
    "           OR\n",
    "           \n",
    "            - concat their contents and predict\n",
    "        - average the two vector of probabilities (we can weight them if we want)\n",
    "\n",
    "all the tresholds tested and the weighting tested led to worse performance : local score : > 1.28 whereas only using the aproach 1 gives 1.28 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                     algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(X_train)\n",
    "X_test_pd_svd = svd_model.transform(X_test)\n",
    "\n",
    "params = svm.best_params_\n",
    "svm_all_train = SVC(gamma='auto', probability=True, C = params[\"C\"])\n",
    "svm_all_train.fit(X_train_pd_svd, local_train.class_codes.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/499"
     ]
    }
   ],
   "source": [
    "th = 2000\n",
    "weight_proba_node = 0.5\n",
    "weight_proba_neighbours = 0.5\n",
    "predictions = []\n",
    "LEN = local_test[\"index\"].values.shape[0]\n",
    "\n",
    "for i, ind in enumerate(local_test[\"index\"].values) :\n",
    "# for ind in [10837] :\n",
    "    sys.stdout.write('\\r'+str(i)+\"/\"+str(LEN))\n",
    "    \n",
    "#     pred_node = svm_all_train.predict_proba(\n",
    "#         svd_model.transform(\n",
    "#             tfidf_vectorize_fit.transform(\n",
    "#                 [\" \".join(whole_preprocessing(ind))]\n",
    "#             )\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "    pred_node = svm_all_train.predict_proba([X_test_pd_svd[i]])\n",
    "    \n",
    "    pred_neighbours_node = []\n",
    "    \n",
    "    for node in edge_list[(edge_list.dest_node == ind)&(edge_list.weight > th) ].start_node.values :\n",
    "        \n",
    "        pred_neighbours_node.append(\n",
    "            svm_all_train.predict_proba(svd_model.transform(tfidf_vectorize_fit.transform([\" \".join(whole_preprocessing(node))])))\n",
    "        )\n",
    "    if pred_neighbours_node == [] :\n",
    "        predictions.append(pred_node[0])\n",
    "    else :\n",
    "        pred_neighbours_node.append(\n",
    "            svm_all_train.predict_proba(\n",
    "                svd_model.transform(\n",
    "                    tfidf_vectorize_fit.transform([\" \".join(CONCAT_txt)])\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        pred_neighbours_node = pred_neighbours_node[0].mean(axis=0).reshape(1, -1)\n",
    "\n",
    "        predictions.append(np.concatenate((pred_node * weight_proba_node,\n",
    "                                           pred_neighbours_node * weight_proba_neighbours\n",
    "                                          ),\n",
    "                                          axis=0).mean(axis=0)\n",
    "                          )\n",
    "####################################\"\"\n",
    "    \n",
    "#     CONCAT_txt =  [\" \".join([\" \".join(whole_preprocessing(node))]) \n",
    "#                    for node in edge_list[(edge_list.dest_node == ind)&(edge_list.weight > th) ].start_node.values]\n",
    "    \n",
    "#     if CONCAT_txt == [] :\n",
    "#         predictions.append(pred_node[0])\n",
    "#     else :\n",
    "#         pred_neighbours_node.append(\n",
    "#             svm_all_train.predict_proba(\n",
    "#                 svd_model.transform(\n",
    "#                     tfidf_vectorize_fit.transform([\" \".join(CONCAT_txt)])\n",
    "#                 )\n",
    "#             )\n",
    "#         )\n",
    "#         pred_neighbours_node = pred_neighbours_node[0].mean(axis=0).reshape(1, -1)\n",
    "\n",
    "#         predictions.append(np.concatenate((pred_node * weight_proba_node,\n",
    "#                                            pred_neighbours_node * weight_proba_neighbours\n",
    "#                                           ),\n",
    "#                                           axis=0).mean(axis=0)\n",
    "#                           )\n",
    "#############################\n",
    "    \n",
    "\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.382377940207255"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score_3(predictions, local_test.class_codes.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Approach 2 :\n",
    "\n",
    "same as approach 1 but we augment the training data set ==> Using the labeled texts and their direct neighbors in the training with the same label : \n",
    "- unweighted\n",
    "- weighted : 70% central node and 30% divided by their number for the neighbors\n",
    "\n",
    "local : 1.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_train = list()\n",
    "new_train_target = list()\n",
    "\n",
    "for i in range(local_train.shape[0]) :\n",
    "    \n",
    "    new_train.append(local_train[\"text_processed_2\"].iloc[i])\n",
    "    cla = local_train[\"class_codes\"].iloc[i]\n",
    "    new_train_target.append(cla)\n",
    "\n",
    "    for node in list(g.neighbors(str(local_train[\"index\"].iloc[i]))): \n",
    "\n",
    "        new_train.append(whole_preprocessing(node))\n",
    "        new_train_target.append(cla)\n",
    "        \n",
    "tfidf_vectorize_fit, X_train, X_test = build_tf_idf(train_data_corpus=pd.Series(new_train), \n",
    "                                                    min_term_frequency=10, \n",
    "                                                    max_term_frequency=5000, \n",
    "                                                    to_transform=local_test.text_processed_2, \n",
    "                                                    tfidf_vectorize_fit=None)\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "logreg.fit(X_train, new_train_target)\n",
    "predictions = logreg.predict_proba(X_test)\n",
    "compute_score_3(predictions, local_test.class_codes.values)\n",
    "\n",
    "weights_train = list()\n",
    "for i in range(local_train.shape[0]) :\n",
    "    weights_train.append(0.7)\n",
    "    n_neighbors = len(list(g.neighbors(str(local_train[\"index\"].iloc[i]))))\n",
    "    for _ in range(n_neighbors):\n",
    "        weights_train.append(0.3/n_neighbors)\n",
    "logreg = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "logreg.fit(X_train, new_train_target, sample_weight = weights_train)\n",
    "predictions = logreg.predict_proba(X_test)\n",
    "compute_score_3(predictions, local_test.class_codes.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SVD + LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3666106983067237"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(X_train)\n",
    "X_test_pd_svd = svd_model.transform(X_test)\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
    "logreg.fit(X_train_pd_svd, local_train.class_codes.values)\n",
    "predictions = logreg.predict_proba(X_test_pd_svd)\n",
    "compute_score_3(predictions, local_test.class_codes.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SVD + NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(X_train)\n",
    "X_test_pd_svd = svd_model.transform(X_test)\n",
    "\n",
    "X_train_pd_svd = torch.FloatTensor(X_train_pd_svd).to(\"cuda\")\n",
    "X_test_pd_svd = torch.FloatTensor(X_test_pd_svd).to(\"cuda\")\n",
    "\n",
    "ytrain = torch.LongTensor(local_train.class_codes.values).to(\"cuda\")\n",
    "ytest = torch.LongTensor(local_test.class_codes.values).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1495, 500])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pd_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape, dropout):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, 30)\n",
    "        self.fc256_256 = nn.Linear(256, 256)\n",
    "        self.fc128_128 = nn.Linear(128, 128)\n",
    "        self.fc64_64 = nn.Linear(64, 64)\n",
    "        \n",
    "        self.fc256_128 = nn.Linear(256, 128)\n",
    "        self.fc128_64 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(30, output_shape)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self.seq = nn.Sequential(self.fc1,\n",
    "                                 self.relu,\n",
    "                                 self.dropout,\n",
    "#                                  nn.Linear(100, 50),\n",
    "#                                  self.relu,\n",
    "#                                  self.dropout,\n",
    "                                 self.fc4\n",
    "                                )\n",
    "                                 \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 loss_train: 2.0923 time: 0.0020s\n",
      "Epoch: 101 loss_train: 1.4237 time: 0.0020s\n",
      "Epoch: 201 loss_train: 1.2338 time: 0.0030s\n",
      "Epoch: 301 loss_train: 1.1098 time: 0.0020s\n",
      "Epoch: 401 loss_train: 1.0439 time: 0.0030s\n",
      "Epoch: 501 loss_train: 0.9772 time: 0.0020s\n",
      "Epoch: 601 loss_train: 0.9592 time: 0.0020s\n",
      "Epoch: 701 loss_train: 0.9184 time: 0.0030s\n",
      "Epoch: 801 loss_train: 0.8631 time: 0.0020s\n",
      "Epoch: 901 loss_train: 0.8371 time: 0.0010s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 2.9358s\n",
      "\n",
      "Test set results: loss= 1.3444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27f7eee6c50>"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "dropout = 0.6\n",
    "\n",
    "net = Net(input_shape=X_train_pd_svd.shape[1],\n",
    "          output_shape=8,\n",
    "          dropout=dropout)\n",
    "net.to(\"cuda\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = net(X_train_pd_svd)\n",
    "    loss_train = criterion(output, ytrain)\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%100 == 0 :\n",
    "        print('Epoch: {:03d}'.format(epoch+1),\n",
    "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\n",
    "    return loss_train.item()\n",
    "def test():\n",
    "    net.eval()\n",
    "    output = net(X_test_pd_svd)\n",
    "    loss_test = criterion(output, ytest)\n",
    "\n",
    "    return loss_test.item()\n",
    "\n",
    "t_total = time.time()\n",
    "training_loss_evolution = []\n",
    "validation_loss_evolution = []\n",
    "for epoch in range(epochs):\n",
    "    training_loss_evolution.append(train(epoch))\n",
    "    validation_loss_evolution.append(test())\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "print()\n",
    "\n",
    "# Testing\n",
    "loss_test = test()\n",
    "print(\"Test set results:\",\n",
    "      \"loss= {:.4f}\".format(loss_test),)\n",
    "\n",
    "# plt.ylim(0,2.5)\n",
    "plt.plot(range(epochs), training_loss_evolution, label=\"training loss\" )\n",
    "plt.plot(range(epochs), validation_loss_evolution, label=\"validation loss\" )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6529888233426884"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()\n",
    "output = net(X_train_pd_svd)\n",
    "compute_score_3(torch.softmax(output, dim=1).detach().cpu().numpy(), ytrain.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3444134069080342"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()\n",
    "output = net(X_test_pd_svd)\n",
    "compute_score_3(torch.softmax(output, dim=1).detach().cpu().numpy(), ytest.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.344298005104065"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(validation_loss_evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tfidf features + GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tfidf ...\n",
      "Building tfidf : Finished\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorize_fit, X_train, X_test = build_tf_idf(train_data_corpus=local_train.text_processed_no_single_words, \n",
    "                                                    min_term_frequency=10, \n",
    "                                                    max_term_frequency=3000, \n",
    "                                                    to_transform=local_test.text_processed_no_single_words, \n",
    "                                                    tfidf_vectorize_fit=None)\n",
    "svd_model = TruncatedSVD(n_components=500, \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=15)\n",
    "\n",
    "X_train_pd_svd = svd_model.fit_transform(X_train)\n",
    "X_test_pd_svd = svd_model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# features = np.concatenate((X_train_pd_svd, X_test_pd_svd))\n",
    "features = np.concatenate((X_train.todense(), X_test.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes :  28002\n",
      "Number of edges :  319498\n"
     ]
    }
   ],
   "source": [
    "g = build_graph()\n",
    "g_sub = nx.subgraph(g, list(local_train[\"index\"].astype(str))+list(local_test[\"index\"].astype(str)))\n",
    "\n",
    "n = g_sub.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = np.array(list(local_train[\"class_codes\"]) + list(local_test[\"class_codes\"]) )\n",
    "n_class = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adj = nx.to_numpy_matrix(g_sub) # Obtains the adjacency matrix\n",
    "adj = normalize_adjacency(adj) # Normalizes the adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx_train = range(local_train.shape[0])\n",
    "idx_test = range(local_train.shape[0], local_train.shape[0]+local_test.shape[0])\n",
    "\n",
    "# Transforms the numpy matrices/vectors to torch tensors\n",
    "features = torch.FloatTensor(features).to(\"cuda\")\n",
    "y = torch.LongTensor(y).to(\"cuda\")\n",
    "adj = torch.FloatTensor(adj).to(\"cuda\")\n",
    "idx_train = torch.LongTensor(idx_train)\n",
    "idx_test = torch.LongTensor(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 200\n",
    "n_hidden_1 = 1024\n",
    "n_hidden_2 = 512\n",
    "n_hidden_3 = 64\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.3\n",
    "\n",
    "model = GNN(features.shape[1], \n",
    "                n_hidden_1, \n",
    "                n_hidden_2, \n",
    "                n_hidden_3,\n",
    "                n_class, \n",
    "                dropout_rate)\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj)\n",
    "    loss_train = loss(output[idx_train], y[idx_train])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch: {:03d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "\n",
    "    return loss_train.item()\n",
    "def test():\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    loss_test = loss(output[idx_test], y[idx_test])\n",
    "\n",
    "    return loss_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 loss_train: 2.0701 time: 2.3746s\n",
      "Epoch: 002 loss_train: 2.0587 time: 0.0828s\n",
      "Epoch: 003 loss_train: 2.0490 time: 0.0787s\n",
      "Epoch: 004 loss_train: 2.0339 time: 0.0767s\n",
      "Epoch: 005 loss_train: 2.0090 time: 0.0738s\n",
      "Epoch: 006 loss_train: 1.9749 time: 0.0708s\n",
      "Epoch: 007 loss_train: 1.9264 time: 0.0724s\n",
      "Epoch: 008 loss_train: 1.8776 time: 0.0746s\n",
      "Epoch: 009 loss_train: 1.8220 time: 0.0708s\n",
      "Epoch: 010 loss_train: 1.8075 time: 0.0735s\n",
      "Epoch: 011 loss_train: 1.7943 time: 0.0724s\n",
      "Epoch: 012 loss_train: 1.7741 time: 0.0703s\n",
      "Epoch: 013 loss_train: 1.7432 time: 0.0738s\n",
      "Epoch: 014 loss_train: 1.7189 time: 0.0738s\n",
      "Epoch: 015 loss_train: 1.6750 time: 0.0748s\n",
      "Epoch: 016 loss_train: 1.6383 time: 0.0747s\n",
      "Epoch: 017 loss_train: 1.6271 time: 0.0728s\n",
      "Epoch: 018 loss_train: 1.5776 time: 0.0733s\n",
      "Epoch: 019 loss_train: 1.5432 time: 0.0708s\n",
      "Epoch: 020 loss_train: 1.4884 time: 0.0739s\n",
      "Epoch: 021 loss_train: 1.4442 time: 0.0725s\n",
      "Epoch: 022 loss_train: 1.3838 time: 0.0728s\n",
      "Epoch: 023 loss_train: 1.3354 time: 0.0729s\n",
      "Epoch: 024 loss_train: 1.3045 time: 0.0728s\n",
      "Epoch: 025 loss_train: 1.2522 time: 0.0708s\n",
      "Epoch: 026 loss_train: 1.2190 time: 0.0719s\n",
      "Epoch: 027 loss_train: 1.1762 time: 0.0754s\n",
      "Epoch: 028 loss_train: 1.1362 time: 0.0698s\n",
      "Epoch: 029 loss_train: 1.0981 time: 0.0738s\n",
      "Epoch: 030 loss_train: 1.0618 time: 0.0718s\n",
      "Epoch: 031 loss_train: 1.0175 time: 0.0718s\n",
      "Epoch: 032 loss_train: 0.9829 time: 0.0738s\n",
      "Epoch: 033 loss_train: 0.9633 time: 0.0742s\n",
      "Epoch: 034 loss_train: 0.9383 time: 0.0718s\n",
      "Epoch: 035 loss_train: 0.8952 time: 0.0738s\n",
      "Epoch: 036 loss_train: 0.8717 time: 0.0732s\n",
      "Epoch: 037 loss_train: 0.8562 time: 0.0728s\n",
      "Epoch: 038 loss_train: 0.8157 time: 0.0738s\n",
      "Epoch: 039 loss_train: 0.7844 time: 0.0718s\n",
      "Epoch: 040 loss_train: 0.7532 time: 0.0742s\n",
      "Epoch: 041 loss_train: 0.7298 time: 0.0723s\n",
      "Epoch: 042 loss_train: 0.7167 time: 0.0751s\n",
      "Epoch: 043 loss_train: 0.6738 time: 0.0728s\n",
      "Epoch: 044 loss_train: 0.6759 time: 0.0718s\n",
      "Epoch: 045 loss_train: 0.6297 time: 0.0738s\n",
      "Epoch: 046 loss_train: 0.6175 time: 0.0738s\n",
      "Epoch: 047 loss_train: 0.6059 time: 0.0738s\n",
      "Epoch: 048 loss_train: 0.5817 time: 0.0708s\n",
      "Epoch: 049 loss_train: 0.5651 time: 0.0728s\n",
      "Epoch: 050 loss_train: 0.5500 time: 0.0734s\n",
      "Epoch: 051 loss_train: 0.5405 time: 0.0734s\n",
      "Epoch: 052 loss_train: 0.5265 time: 0.0709s\n",
      "Epoch: 053 loss_train: 0.5126 time: 0.0765s\n",
      "Epoch: 054 loss_train: 0.4963 time: 0.0718s\n",
      "Epoch: 055 loss_train: 0.4828 time: 0.0728s\n",
      "Epoch: 056 loss_train: 0.4754 time: 0.0747s\n",
      "Epoch: 057 loss_train: 0.4892 time: 0.0714s\n",
      "Epoch: 058 loss_train: 0.4595 time: 0.0753s\n",
      "Epoch: 059 loss_train: 0.4555 time: 0.0718s\n",
      "Epoch: 060 loss_train: 0.4491 time: 0.0728s\n",
      "Epoch: 061 loss_train: 0.4390 time: 0.0718s\n",
      "Epoch: 062 loss_train: 0.4319 time: 0.0745s\n",
      "Epoch: 063 loss_train: 0.4270 time: 0.0738s\n",
      "Epoch: 064 loss_train: 0.4053 time: 0.0728s\n",
      "Epoch: 065 loss_train: 0.4140 time: 0.0738s\n",
      "Epoch: 066 loss_train: 0.4059 time: 0.0746s\n",
      "Epoch: 067 loss_train: 0.4049 time: 0.0748s\n",
      "Epoch: 068 loss_train: 0.3900 time: 0.0724s\n",
      "Epoch: 069 loss_train: 0.3843 time: 0.0736s\n",
      "Epoch: 070 loss_train: 0.3836 time: 0.0758s\n",
      "Epoch: 071 loss_train: 0.3852 time: 0.0728s\n",
      "Epoch: 072 loss_train: 0.3751 time: 0.0730s\n",
      "Epoch: 073 loss_train: 0.3765 time: 0.0737s\n",
      "Epoch: 074 loss_train: 0.3631 time: 0.0738s\n",
      "Epoch: 075 loss_train: 0.3642 time: 0.0718s\n",
      "Epoch: 076 loss_train: 0.3597 time: 0.0752s\n",
      "Epoch: 077 loss_train: 0.3454 time: 0.0728s\n",
      "Epoch: 078 loss_train: 0.3518 time: 0.0747s\n",
      "Epoch: 079 loss_train: 0.3491 time: 0.0727s\n",
      "Epoch: 080 loss_train: 0.3525 time: 0.0738s\n",
      "Epoch: 081 loss_train: 0.3447 time: 0.0728s\n",
      "Epoch: 082 loss_train: 0.3392 time: 0.0718s\n",
      "Epoch: 083 loss_train: 0.3327 time: 0.0738s\n",
      "Epoch: 084 loss_train: 0.3235 time: 0.0738s\n",
      "Epoch: 085 loss_train: 0.3291 time: 0.0758s\n",
      "Epoch: 086 loss_train: 0.3293 time: 0.0728s\n",
      "Epoch: 087 loss_train: 0.3283 time: 0.0748s\n",
      "Epoch: 088 loss_train: 0.3196 time: 0.0730s\n",
      "Epoch: 089 loss_train: 0.3169 time: 0.0724s\n",
      "Epoch: 090 loss_train: 0.3110 time: 0.0734s\n",
      "Epoch: 091 loss_train: 0.3088 time: 0.0738s\n",
      "Epoch: 092 loss_train: 0.3071 time: 0.0729s\n",
      "Epoch: 093 loss_train: 0.3063 time: 0.0718s\n",
      "Epoch: 094 loss_train: 0.3006 time: 0.0748s\n",
      "Epoch: 095 loss_train: 0.3049 time: 0.0738s\n",
      "Epoch: 096 loss_train: 0.2991 time: 0.0748s\n",
      "Epoch: 097 loss_train: 0.2931 time: 0.0757s\n",
      "Epoch: 098 loss_train: 0.2880 time: 0.0738s\n",
      "Epoch: 099 loss_train: 0.2975 time: 0.0738s\n",
      "Epoch: 100 loss_train: 0.2850 time: 0.0708s\n",
      "Epoch: 101 loss_train: 0.2903 time: 0.0728s\n",
      "Epoch: 102 loss_train: 0.2875 time: 0.0738s\n",
      "Epoch: 103 loss_train: 0.2909 time: 0.0742s\n",
      "Epoch: 104 loss_train: 0.2822 time: 0.0741s\n",
      "Epoch: 105 loss_train: 0.2840 time: 0.0738s\n",
      "Epoch: 106 loss_train: 0.2781 time: 0.0728s\n",
      "Epoch: 107 loss_train: 0.2820 time: 0.0728s\n",
      "Epoch: 108 loss_train: 0.2861 time: 0.0758s\n",
      "Epoch: 109 loss_train: 0.2773 time: 0.0738s\n",
      "Epoch: 110 loss_train: 0.2595 time: 0.0738s\n",
      "Epoch: 111 loss_train: 0.2698 time: 0.0734s\n",
      "Epoch: 112 loss_train: 0.2639 time: 0.0743s\n",
      "Epoch: 113 loss_train: 0.2565 time: 0.0748s\n",
      "Epoch: 114 loss_train: 0.2600 time: 0.0722s\n",
      "Epoch: 115 loss_train: 0.2681 time: 0.0743s\n",
      "Epoch: 116 loss_train: 0.2695 time: 0.0723s\n",
      "Epoch: 117 loss_train: 0.2689 time: 0.0738s\n",
      "Epoch: 118 loss_train: 0.2521 time: 0.0738s\n",
      "Epoch: 119 loss_train: 0.2546 time: 0.0732s\n",
      "Epoch: 120 loss_train: 0.2647 time: 0.0748s\n",
      "Epoch: 121 loss_train: 0.2510 time: 0.0735s\n",
      "Epoch: 122 loss_train: 0.2449 time: 0.0754s\n",
      "Epoch: 123 loss_train: 0.2579 time: 0.0738s\n",
      "Epoch: 124 loss_train: 0.2583 time: 0.0718s\n",
      "Epoch: 125 loss_train: 0.2468 time: 0.0728s\n",
      "Epoch: 126 loss_train: 0.2531 time: 0.0738s\n",
      "Epoch: 127 loss_train: 0.2459 time: 0.0728s\n",
      "Epoch: 128 loss_train: 0.2398 time: 0.0728s\n",
      "Epoch: 129 loss_train: 0.2358 time: 0.0748s\n",
      "Epoch: 130 loss_train: 0.2448 time: 0.0718s\n",
      "Epoch: 131 loss_train: 0.2453 time: 0.0724s\n",
      "Epoch: 132 loss_train: 0.2437 time: 0.0738s\n",
      "Epoch: 133 loss_train: 0.2383 time: 0.0738s\n",
      "Epoch: 134 loss_train: 0.2327 time: 0.0708s\n",
      "Epoch: 135 loss_train: 0.2359 time: 0.0719s\n",
      "Epoch: 136 loss_train: 0.2487 time: 0.0728s\n",
      "Epoch: 137 loss_train: 0.2391 time: 0.0738s\n",
      "Epoch: 138 loss_train: 0.2289 time: 0.0723s\n",
      "Epoch: 139 loss_train: 0.2237 time: 0.0738s\n",
      "Epoch: 140 loss_train: 0.2367 time: 0.0728s\n",
      "Epoch: 141 loss_train: 0.2318 time: 0.0737s\n",
      "Epoch: 142 loss_train: 0.2274 time: 0.0748s\n",
      "Epoch: 143 loss_train: 0.2106 time: 0.0738s\n",
      "Epoch: 144 loss_train: 0.2268 time: 0.0731s\n",
      "Epoch: 145 loss_train: 0.2248 time: 0.0758s\n",
      "Epoch: 146 loss_train: 0.2183 time: 0.0738s\n",
      "Epoch: 147 loss_train: 0.2256 time: 0.0714s\n",
      "Epoch: 148 loss_train: 0.2242 time: 0.0728s\n",
      "Epoch: 149 loss_train: 0.2155 time: 0.0774s\n",
      "Epoch: 150 loss_train: 0.2184 time: 0.0718s\n",
      "Epoch: 151 loss_train: 0.2182 time: 0.0728s\n",
      "Epoch: 152 loss_train: 0.2261 time: 0.0745s\n",
      "Epoch: 153 loss_train: 0.2172 time: 0.0725s\n",
      "Epoch: 154 loss_train: 0.2171 time: 0.0738s\n",
      "Epoch: 155 loss_train: 0.2188 time: 0.0738s\n",
      "Epoch: 156 loss_train: 0.2040 time: 0.0702s\n",
      "Epoch: 157 loss_train: 0.2057 time: 0.0748s\n",
      "Epoch: 158 loss_train: 0.2092 time: 0.0755s\n",
      "Epoch: 159 loss_train: 0.2176 time: 0.0738s\n",
      "Epoch: 160 loss_train: 0.2112 time: 0.0738s\n",
      "Epoch: 161 loss_train: 0.2039 time: 0.0735s\n",
      "Epoch: 162 loss_train: 0.2133 time: 0.0745s\n",
      "Epoch: 163 loss_train: 0.2165 time: 0.0738s\n",
      "Epoch: 164 loss_train: 0.2104 time: 0.0738s\n",
      "Epoch: 165 loss_train: 0.2160 time: 0.0728s\n",
      "Epoch: 166 loss_train: 0.2075 time: 0.0748s\n",
      "Epoch: 167 loss_train: 0.2064 time: 0.0718s\n",
      "Epoch: 168 loss_train: 0.2106 time: 0.0737s\n",
      "Epoch: 169 loss_train: 0.2020 time: 0.0718s\n",
      "Epoch: 170 loss_train: 0.2043 time: 0.0729s\n",
      "Epoch: 171 loss_train: 0.2003 time: 0.0730s\n",
      "Epoch: 172 loss_train: 0.2069 time: 0.0749s\n",
      "Epoch: 173 loss_train: 0.1946 time: 0.0733s\n",
      "Epoch: 174 loss_train: 0.2014 time: 0.0744s\n",
      "Epoch: 175 loss_train: 0.1988 time: 0.0738s\n",
      "Epoch: 176 loss_train: 0.1988 time: 0.0718s\n",
      "Epoch: 177 loss_train: 0.1958 time: 0.0728s\n",
      "Epoch: 178 loss_train: 0.1945 time: 0.0723s\n",
      "Epoch: 179 loss_train: 0.2001 time: 0.0738s\n",
      "Epoch: 180 loss_train: 0.1946 time: 0.0741s\n",
      "Epoch: 181 loss_train: 0.1966 time: 0.0741s\n",
      "Epoch: 182 loss_train: 0.1936 time: 0.0738s\n",
      "Epoch: 183 loss_train: 0.2016 time: 0.0727s\n",
      "Epoch: 184 loss_train: 0.1951 time: 0.0738s\n",
      "Epoch: 185 loss_train: 0.2013 time: 0.0728s\n",
      "Epoch: 186 loss_train: 0.1896 time: 0.0746s\n",
      "Epoch: 187 loss_train: 0.1891 time: 0.0728s\n",
      "Epoch: 188 loss_train: 0.1996 time: 0.0718s\n",
      "Epoch: 189 loss_train: 0.1852 time: 0.0758s\n",
      "Epoch: 190 loss_train: 0.1982 time: 0.0738s\n",
      "Epoch: 191 loss_train: 0.1898 time: 0.0738s\n",
      "Epoch: 192 loss_train: 0.1818 time: 0.0748s\n",
      "Epoch: 193 loss_train: 0.1940 time: 0.0728s\n",
      "Epoch: 194 loss_train: 0.1936 time: 0.0738s\n",
      "Epoch: 195 loss_train: 0.1818 time: 0.0708s\n",
      "Epoch: 196 loss_train: 0.1950 time: 0.0735s\n",
      "Epoch: 197 loss_train: 0.1865 time: 0.0758s\n",
      "Epoch: 198 loss_train: 0.1781 time: 0.0713s\n",
      "Epoch: 199 loss_train: 0.1750 time: 0.0738s\n",
      "Epoch: 200 loss_train: 0.1844 time: 0.0763s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.9428s\n",
      "\n",
      "Test set results: loss= 8.6205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1df2c1cd470>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_total = time.time()\n",
    "training_loss_evolution = []\n",
    "validation_loss_evolution = []\n",
    "for epoch in range(epochs):\n",
    "    training_loss_evolution.append(train(epoch))\n",
    "    validation_loss_evolution.append(test())\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "print()\n",
    "\n",
    "# Testing\n",
    "loss_test = test()\n",
    "print(\"Test set results:\",\n",
    "      \"loss= {:.4f}\".format(loss_test),)\n",
    "\n",
    "plt.ylim(0,2.5)\n",
    "plt.plot(range(epochs), training_loss_evolution, label=\"training loss\" )\n",
    "plt.plot(range(epochs), validation_loss_evolution, label=\"validation loss\" )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying a bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to run 5. Check vocab coverage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_voc = 150000\n",
    "max_len = 20\n",
    "def make_data(X):\n",
    "    t = Tokenizer(num_words=len_voc)\n",
    "    t.fit_on_texts(X)\n",
    "    X = t.texts_to_sequences(X)\n",
    "    X = pad_sequences(X, maxlen=max_len)\n",
    "    return X, t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, word_index = make_data(local_train[\"text_processed_no_dupl\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494194"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = local_train['class'].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embed_matrix(embeddings_index, word_index, len_voc):\n",
    "    embedding_matrix = np.zeros((len(word_index)+1, 300))\n",
    "    for word, i in word_index.items():\n",
    "        if i <= len_voc:   \n",
    "            try :\n",
    "                embedding_vector = nlp.vocab.vectors[nlp.vocab.strings[word]]\n",
    "            except :\n",
    "                embedding_vector = np.zeros(300)\n",
    "\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else :\n",
    "            pass\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = make_embed_matrix(nlp.vocab.strings, word_index, len_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Bidirectional, LSTM, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, Input, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(embedding_matrix, embed_size=300, loss='categorical_crossentropy'):\n",
    "    inp    = Input(shape=(max_len,))\n",
    "    x      = Embedding(len(embedding_matrix), embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x      = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x      = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    \n",
    "    avg_pl = GlobalAveragePooling1D()(x)\n",
    "    max_pl = GlobalMaxPooling1D()(x)\n",
    "    concat = concatenate([avg_pl, max_pl])\n",
    "    dense  = Dense(32, activation=\"relu\")(concat)\n",
    "    drop   = Dropout(0.1)(dense)\n",
    "    output = Dense(8, activation=\"sigmoid\")(drop)\n",
    "    \n",
    "    model  = Model(inputs=inp, outputs=output)\n",
    "    model.compile(loss=loss, optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 20, 300)      148258500   input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 20, 128)      186880      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 20, 128)      98816       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           8224        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            264         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 148,552,684\n",
      "Trainable params: 294,184\n",
      "Non-trainable params: 148,258,500\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = ModelCheckpoint('weights.hdf5', monitor=\"val_loss\", mode=\"min\", verbose=True, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1121 samples, validate on 374 samples\n",
      "Epoch 1/50\n",
      "1121/1121 [==============================] - ETA: 3:54 - loss: 2.0717 - accuracy: 0.18 - ETA: 1:56 - loss: 2.0670 - accuracy: 0.18 - ETA: 1:16 - loss: 2.0628 - accuracy: 0.21 - ETA: 56s - loss: 2.0592 - accuracy: 0.2188 - ETA: 44s - loss: 2.0552 - accuracy: 0.231 - ETA: 36s - loss: 2.0461 - accuracy: 0.250 - ETA: 30s - loss: 2.0424 - accuracy: 0.250 - ETA: 26s - loss: 2.0377 - accuracy: 0.242 - ETA: 22s - loss: 2.0329 - accuracy: 0.243 - ETA: 19s - loss: 2.0339 - accuracy: 0.243 - ETA: 17s - loss: 2.0252 - accuracy: 0.244 - ETA: 15s - loss: 2.0249 - accuracy: 0.247 - ETA: 13s - loss: 2.0203 - accuracy: 0.250 - ETA: 12s - loss: 2.0217 - accuracy: 0.243 - ETA: 11s - loss: 2.0135 - accuracy: 0.243 - ETA: 9s - loss: 2.0020 - accuracy: 0.246 - ETA: 8s - loss: 1.9989 - accuracy: 0.24 - ETA: 8s - loss: 1.9909 - accuracy: 0.25 - ETA: 7s - loss: 1.9848 - accuracy: 0.25 - ETA: 6s - loss: 1.9895 - accuracy: 0.25 - ETA: 5s - loss: 1.9855 - accuracy: 0.25 - ETA: 5s - loss: 1.9726 - accuracy: 0.25 - ETA: 4s - loss: 1.9772 - accuracy: 0.25 - ETA: 4s - loss: 1.9696 - accuracy: 0.26 - ETA: 3s - loss: 1.9616 - accuracy: 0.26 - ETA: 3s - loss: 1.9614 - accuracy: 0.26 - ETA: 2s - loss: 1.9542 - accuracy: 0.26 - ETA: 2s - loss: 1.9444 - accuracy: 0.27 - ETA: 1s - loss: 1.9483 - accuracy: 0.28 - ETA: 1s - loss: 1.9423 - accuracy: 0.27 - ETA: 1s - loss: 1.9400 - accuracy: 0.28 - ETA: 0s - loss: 1.9378 - accuracy: 0.28 - ETA: 0s - loss: 1.9326 - accuracy: 0.28 - ETA: 0s - loss: 1.9258 - accuracy: 0.28 - ETA: 0s - loss: 1.9247 - accuracy: 0.29 - 11s 10ms/step - loss: 1.9240 - accuracy: 0.2908 - val_loss: 1.8216 - val_accuracy: 0.2941\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.82158, saving model to weights.hdf5\n",
      "Epoch 2/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.7564 - accuracy: 0.28 - ETA: 2s - loss: 1.7932 - accuracy: 0.31 - ETA: 2s - loss: 1.7813 - accuracy: 0.32 - ETA: 2s - loss: 1.7431 - accuracy: 0.32 - ETA: 2s - loss: 1.7704 - accuracy: 0.33 - ETA: 2s - loss: 1.7683 - accuracy: 0.33 - ETA: 2s - loss: 1.7761 - accuracy: 0.33 - ETA: 1s - loss: 1.7630 - accuracy: 0.35 - ETA: 1s - loss: 1.7512 - accuracy: 0.34 - ETA: 1s - loss: 1.7359 - accuracy: 0.36 - ETA: 1s - loss: 1.7260 - accuracy: 0.35 - ETA: 1s - loss: 1.7260 - accuracy: 0.34 - ETA: 1s - loss: 1.7482 - accuracy: 0.33 - ETA: 1s - loss: 1.7598 - accuracy: 0.32 - ETA: 1s - loss: 1.7569 - accuracy: 0.32 - ETA: 1s - loss: 1.7578 - accuracy: 0.32 - ETA: 1s - loss: 1.7644 - accuracy: 0.31 - ETA: 1s - loss: 1.7661 - accuracy: 0.31 - ETA: 1s - loss: 1.7622 - accuracy: 0.31 - ETA: 1s - loss: 1.7598 - accuracy: 0.32 - ETA: 1s - loss: 1.7602 - accuracy: 0.31 - ETA: 0s - loss: 1.7570 - accuracy: 0.31 - ETA: 0s - loss: 1.7590 - accuracy: 0.30 - ETA: 0s - loss: 1.7573 - accuracy: 0.30 - ETA: 0s - loss: 1.7620 - accuracy: 0.30 - ETA: 0s - loss: 1.7557 - accuracy: 0.30 - ETA: 0s - loss: 1.7494 - accuracy: 0.30 - ETA: 0s - loss: 1.7469 - accuracy: 0.30 - ETA: 0s - loss: 1.7489 - accuracy: 0.30 - ETA: 0s - loss: 1.7554 - accuracy: 0.30 - ETA: 0s - loss: 1.7560 - accuracy: 0.30 - ETA: 0s - loss: 1.7603 - accuracy: 0.30 - ETA: 0s - loss: 1.7547 - accuracy: 0.30 - ETA: 0s - loss: 1.7609 - accuracy: 0.30 - ETA: 0s - loss: 1.7610 - accuracy: 0.31 - 3s 3ms/step - loss: 1.7612 - accuracy: 0.3104 - val_loss: 1.7809 - val_accuracy: 0.3235\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.82158 to 1.78088, saving model to weights.hdf5\n",
      "Epoch 3/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.6973 - accuracy: 0.31 - ETA: 5s - loss: 1.6591 - accuracy: 0.39 - ETA: 4s - loss: 1.7236 - accuracy: 0.31 - ETA: 4s - loss: 1.7291 - accuracy: 0.30 - ETA: 3s - loss: 1.7101 - accuracy: 0.32 - ETA: 3s - loss: 1.6855 - accuracy: 0.33 - ETA: 2s - loss: 1.6675 - accuracy: 0.34 - ETA: 2s - loss: 1.6681 - accuracy: 0.33 - ETA: 2s - loss: 1.6672 - accuracy: 0.32 - ETA: 2s - loss: 1.6815 - accuracy: 0.32 - ETA: 2s - loss: 1.6792 - accuracy: 0.34 - ETA: 2s - loss: 1.6792 - accuracy: 0.34 - ETA: 1s - loss: 1.6725 - accuracy: 0.34 - ETA: 1s - loss: 1.6843 - accuracy: 0.33 - ETA: 1s - loss: 1.6903 - accuracy: 0.32 - ETA: 1s - loss: 1.6847 - accuracy: 0.32 - ETA: 1s - loss: 1.6876 - accuracy: 0.32 - ETA: 1s - loss: 1.6876 - accuracy: 0.32 - ETA: 1s - loss: 1.6850 - accuracy: 0.32 - ETA: 1s - loss: 1.6951 - accuracy: 0.31 - ETA: 1s - loss: 1.6916 - accuracy: 0.31 - ETA: 1s - loss: 1.6923 - accuracy: 0.31 - ETA: 0s - loss: 1.7032 - accuracy: 0.31 - ETA: 0s - loss: 1.6964 - accuracy: 0.31 - ETA: 0s - loss: 1.6893 - accuracy: 0.31 - ETA: 0s - loss: 1.6926 - accuracy: 0.30 - ETA: 0s - loss: 1.6936 - accuracy: 0.30 - ETA: 0s - loss: 1.6976 - accuracy: 0.30 - ETA: 0s - loss: 1.7000 - accuracy: 0.31 - ETA: 0s - loss: 1.6960 - accuracy: 0.31 - ETA: 0s - loss: 1.6959 - accuracy: 0.31 - ETA: 0s - loss: 1.6924 - accuracy: 0.31 - ETA: 0s - loss: 1.6907 - accuracy: 0.31 - ETA: 0s - loss: 1.6909 - accuracy: 0.31 - ETA: 0s - loss: 1.6851 - accuracy: 0.31 - 3s 3ms/step - loss: 1.6852 - accuracy: 0.3149 - val_loss: 1.8100 - val_accuracy: 0.3342\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.78088\n",
      "Epoch 4/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.6307 - accuracy: 0.40 - ETA: 2s - loss: 1.5538 - accuracy: 0.46 - ETA: 2s - loss: 1.6661 - accuracy: 0.39 - ETA: 2s - loss: 1.5831 - accuracy: 0.39 - ETA: 2s - loss: 1.5759 - accuracy: 0.36 - ETA: 2s - loss: 1.5569 - accuracy: 0.38 - ETA: 2s - loss: 1.5388 - accuracy: 0.38 - ETA: 1s - loss: 1.5667 - accuracy: 0.38 - ETA: 1s - loss: 1.5760 - accuracy: 0.38 - ETA: 1s - loss: 1.5800 - accuracy: 0.37 - ETA: 1s - loss: 1.5996 - accuracy: 0.35 - ETA: 1s - loss: 1.5861 - accuracy: 0.35 - ETA: 1s - loss: 1.5982 - accuracy: 0.35 - ETA: 1s - loss: 1.6124 - accuracy: 0.35 - ETA: 1s - loss: 1.6090 - accuracy: 0.35 - ETA: 1s - loss: 1.6068 - accuracy: 0.36 - ETA: 1s - loss: 1.6212 - accuracy: 0.36 - ETA: 1s - loss: 1.6217 - accuracy: 0.35 - ETA: 1s - loss: 1.6223 - accuracy: 0.36 - ETA: 1s - loss: 1.6225 - accuracy: 0.35 - ETA: 1s - loss: 1.6268 - accuracy: 0.35 - ETA: 0s - loss: 1.6330 - accuracy: 0.35 - ETA: 0s - loss: 1.6257 - accuracy: 0.35 - ETA: 0s - loss: 1.6342 - accuracy: 0.35 - ETA: 0s - loss: 1.6277 - accuracy: 0.36 - ETA: 0s - loss: 1.6258 - accuracy: 0.35 - ETA: 0s - loss: 1.6313 - accuracy: 0.36 - ETA: 0s - loss: 1.6262 - accuracy: 0.36 - ETA: 0s - loss: 1.6255 - accuracy: 0.35 - ETA: 0s - loss: 1.6221 - accuracy: 0.35 - ETA: 0s - loss: 1.6296 - accuracy: 0.35 - ETA: 0s - loss: 1.6253 - accuracy: 0.35 - ETA: 0s - loss: 1.6273 - accuracy: 0.35 - ETA: 0s - loss: 1.6249 - accuracy: 0.35 - ETA: 0s - loss: 1.6297 - accuracy: 0.35 - 3s 3ms/step - loss: 1.6295 - accuracy: 0.3550 - val_loss: 1.8339 - val_accuracy: 0.3422\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.78088\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.4429 - accuracy: 0.40 - ETA: 2s - loss: 1.4047 - accuracy: 0.46 - ETA: 2s - loss: 1.4736 - accuracy: 0.42 - ETA: 2s - loss: 1.4570 - accuracy: 0.43 - ETA: 2s - loss: 1.4768 - accuracy: 0.44 - ETA: 2s - loss: 1.4892 - accuracy: 0.44 - ETA: 2s - loss: 1.5128 - accuracy: 0.41 - ETA: 2s - loss: 1.5013 - accuracy: 0.40 - ETA: 1s - loss: 1.4972 - accuracy: 0.40 - ETA: 1s - loss: 1.5151 - accuracy: 0.40 - ETA: 1s - loss: 1.5107 - accuracy: 0.40 - ETA: 1s - loss: 1.5184 - accuracy: 0.39 - ETA: 1s - loss: 1.5445 - accuracy: 0.38 - ETA: 1s - loss: 1.5342 - accuracy: 0.39 - ETA: 1s - loss: 1.5294 - accuracy: 0.39 - ETA: 1s - loss: 1.5340 - accuracy: 0.38 - ETA: 1s - loss: 1.5370 - accuracy: 0.38 - ETA: 1s - loss: 1.5345 - accuracy: 0.38 - ETA: 1s - loss: 1.5347 - accuracy: 0.39 - ETA: 1s - loss: 1.5375 - accuracy: 0.39 - ETA: 1s - loss: 1.5441 - accuracy: 0.39 - ETA: 0s - loss: 1.5459 - accuracy: 0.39 - ETA: 0s - loss: 1.5449 - accuracy: 0.38 - ETA: 0s - loss: 1.5481 - accuracy: 0.38 - ETA: 0s - loss: 1.5436 - accuracy: 0.39 - ETA: 0s - loss: 1.5426 - accuracy: 0.38 - ETA: 0s - loss: 1.5469 - accuracy: 0.38 - ETA: 0s - loss: 1.5524 - accuracy: 0.38 - ETA: 0s - loss: 1.5493 - accuracy: 0.38 - ETA: 0s - loss: 1.5533 - accuracy: 0.38 - ETA: 0s - loss: 1.5540 - accuracy: 0.37 - ETA: 0s - loss: 1.5522 - accuracy: 0.37 - ETA: 0s - loss: 1.5478 - accuracy: 0.38 - ETA: 0s - loss: 1.5460 - accuracy: 0.38 - ETA: 0s - loss: 1.5458 - accuracy: 0.38 - 3s 3ms/step - loss: 1.5453 - accuracy: 0.3818 - val_loss: 1.8497 - val_accuracy: 0.3449\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.78088\n",
      "Epoch 6/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.4071 - accuracy: 0.40 - ETA: 2s - loss: 1.4280 - accuracy: 0.43 - ETA: 2s - loss: 1.4605 - accuracy: 0.38 - ETA: 2s - loss: 1.4427 - accuracy: 0.39 - ETA: 2s - loss: 1.4791 - accuracy: 0.36 - ETA: 2s - loss: 1.4749 - accuracy: 0.36 - ETA: 2s - loss: 1.4828 - accuracy: 0.35 - ETA: 1s - loss: 1.4871 - accuracy: 0.35 - ETA: 1s - loss: 1.4812 - accuracy: 0.36 - ETA: 1s - loss: 1.4750 - accuracy: 0.35 - ETA: 1s - loss: 1.4751 - accuracy: 0.34 - ETA: 1s - loss: 1.4854 - accuracy: 0.34 - ETA: 1s - loss: 1.5014 - accuracy: 0.35 - ETA: 1s - loss: 1.4982 - accuracy: 0.36 - ETA: 1s - loss: 1.5102 - accuracy: 0.35 - ETA: 1s - loss: 1.5044 - accuracy: 0.35 - ETA: 1s - loss: 1.5025 - accuracy: 0.36 - ETA: 1s - loss: 1.5016 - accuracy: 0.35 - ETA: 1s - loss: 1.4995 - accuracy: 0.36 - ETA: 1s - loss: 1.5068 - accuracy: 0.35 - ETA: 1s - loss: 1.5053 - accuracy: 0.36 - ETA: 0s - loss: 1.5060 - accuracy: 0.36 - ETA: 0s - loss: 1.5081 - accuracy: 0.36 - ETA: 0s - loss: 1.5105 - accuracy: 0.36 - ETA: 0s - loss: 1.5113 - accuracy: 0.36 - ETA: 0s - loss: 1.5041 - accuracy: 0.36 - ETA: 0s - loss: 1.5042 - accuracy: 0.36 - ETA: 0s - loss: 1.4996 - accuracy: 0.37 - ETA: 0s - loss: 1.5003 - accuracy: 0.37 - ETA: 0s - loss: 1.5118 - accuracy: 0.37 - ETA: 0s - loss: 1.5035 - accuracy: 0.37 - ETA: 0s - loss: 1.5020 - accuracy: 0.37 - ETA: 0s - loss: 1.4995 - accuracy: 0.36 - ETA: 0s - loss: 1.5006 - accuracy: 0.37 - ETA: 0s - loss: 1.5046 - accuracy: 0.36 - 3s 3ms/step - loss: 1.5050 - accuracy: 0.3675 - val_loss: 1.8482 - val_accuracy: 0.3476\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.78088\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 7/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.6306 - accuracy: 0.31 - ETA: 2s - loss: 1.5505 - accuracy: 0.32 - ETA: 2s - loss: 1.5312 - accuracy: 0.35 - ETA: 2s - loss: 1.5516 - accuracy: 0.34 - ETA: 2s - loss: 1.5489 - accuracy: 0.35 - ETA: 2s - loss: 1.5587 - accuracy: 0.36 - ETA: 2s - loss: 1.5636 - accuracy: 0.37 - ETA: 1s - loss: 1.5470 - accuracy: 0.35 - ETA: 1s - loss: 1.5163 - accuracy: 0.37 - ETA: 1s - loss: 1.5223 - accuracy: 0.37 - ETA: 1s - loss: 1.5222 - accuracy: 0.38 - ETA: 1s - loss: 1.5218 - accuracy: 0.37 - ETA: 1s - loss: 1.5334 - accuracy: 0.37 - ETA: 1s - loss: 1.5238 - accuracy: 0.38 - ETA: 1s - loss: 1.5241 - accuracy: 0.38 - ETA: 1s - loss: 1.5158 - accuracy: 0.38 - ETA: 1s - loss: 1.5147 - accuracy: 0.38 - ETA: 1s - loss: 1.5113 - accuracy: 0.38 - ETA: 1s - loss: 1.5078 - accuracy: 0.38 - ETA: 1s - loss: 1.5023 - accuracy: 0.39 - ETA: 1s - loss: 1.5019 - accuracy: 0.38 - ETA: 0s - loss: 1.5062 - accuracy: 0.38 - ETA: 0s - loss: 1.5025 - accuracy: 0.38 - ETA: 0s - loss: 1.5002 - accuracy: 0.38 - ETA: 0s - loss: 1.5012 - accuracy: 0.39 - ETA: 0s - loss: 1.4975 - accuracy: 0.38 - ETA: 0s - loss: 1.4956 - accuracy: 0.38 - ETA: 0s - loss: 1.4906 - accuracy: 0.38 - ETA: 0s - loss: 1.4931 - accuracy: 0.38 - ETA: 0s - loss: 1.4939 - accuracy: 0.38 - ETA: 0s - loss: 1.4946 - accuracy: 0.37 - ETA: 0s - loss: 1.5007 - accuracy: 0.37 - ETA: 0s - loss: 1.4969 - accuracy: 0.37 - ETA: 0s - loss: 1.4914 - accuracy: 0.37 - ETA: 0s - loss: 1.4936 - accuracy: 0.37 - 3s 3ms/step - loss: 1.4931 - accuracy: 0.3764 - val_loss: 1.8485 - val_accuracy: 0.3449\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.78088\n",
      "Epoch 8/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.7573 - accuracy: 0.28 - ETA: 2s - loss: 1.6294 - accuracy: 0.35 - ETA: 2s - loss: 1.5599 - accuracy: 0.38 - ETA: 2s - loss: 1.5533 - accuracy: 0.37 - ETA: 2s - loss: 1.5427 - accuracy: 0.35 - ETA: 2s - loss: 1.5371 - accuracy: 0.35 - ETA: 2s - loss: 1.5421 - accuracy: 0.33 - ETA: 1s - loss: 1.5891 - accuracy: 0.33 - ETA: 1s - loss: 1.5976 - accuracy: 0.32 - ETA: 1s - loss: 1.5787 - accuracy: 0.34 - ETA: 1s - loss: 1.5459 - accuracy: 0.34 - ETA: 1s - loss: 1.5411 - accuracy: 0.35 - ETA: 1s - loss: 1.5264 - accuracy: 0.36 - ETA: 1s - loss: 1.5487 - accuracy: 0.35 - ETA: 1s - loss: 1.5417 - accuracy: 0.37 - ETA: 1s - loss: 1.5266 - accuracy: 0.37 - ETA: 1s - loss: 1.5187 - accuracy: 0.37 - ETA: 1s - loss: 1.5098 - accuracy: 0.37 - ETA: 1s - loss: 1.5039 - accuracy: 0.37 - ETA: 1s - loss: 1.4995 - accuracy: 0.38 - ETA: 1s - loss: 1.4922 - accuracy: 0.38 - ETA: 0s - loss: 1.4925 - accuracy: 0.38 - ETA: 0s - loss: 1.4946 - accuracy: 0.38 - ETA: 0s - loss: 1.4971 - accuracy: 0.38 - ETA: 0s - loss: 1.4916 - accuracy: 0.38 - ETA: 0s - loss: 1.4837 - accuracy: 0.38 - ETA: 0s - loss: 1.4775 - accuracy: 0.38 - ETA: 0s - loss: 1.4798 - accuracy: 0.38 - ETA: 0s - loss: 1.4787 - accuracy: 0.39 - ETA: 0s - loss: 1.4821 - accuracy: 0.38 - ETA: 0s - loss: 1.4846 - accuracy: 0.39 - ETA: 0s - loss: 1.4878 - accuracy: 0.38 - ETA: 0s - loss: 1.4925 - accuracy: 0.38 - ETA: 0s - loss: 1.4928 - accuracy: 0.39 - ETA: 0s - loss: 1.4978 - accuracy: 0.39 - 3s 3ms/step - loss: 1.4976 - accuracy: 0.3916 - val_loss: 1.8504 - val_accuracy: 0.3449\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.78088\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1121/1121 [==============================] - ETA: 2s - loss: 1.5684 - accuracy: 0.37 - ETA: 2s - loss: 1.5866 - accuracy: 0.35 - ETA: 2s - loss: 1.5593 - accuracy: 0.34 - ETA: 2s - loss: 1.5012 - accuracy: 0.38 - ETA: 2s - loss: 1.5113 - accuracy: 0.39 - ETA: 2s - loss: 1.4967 - accuracy: 0.39 - ETA: 1s - loss: 1.5053 - accuracy: 0.39 - ETA: 1s - loss: 1.5042 - accuracy: 0.38 - ETA: 1s - loss: 1.5331 - accuracy: 0.37 - ETA: 1s - loss: 1.5341 - accuracy: 0.38 - ETA: 1s - loss: 1.5200 - accuracy: 0.39 - ETA: 1s - loss: 1.5044 - accuracy: 0.39 - ETA: 1s - loss: 1.4979 - accuracy: 0.39 - ETA: 1s - loss: 1.5048 - accuracy: 0.39 - ETA: 1s - loss: 1.5067 - accuracy: 0.38 - ETA: 1s - loss: 1.5147 - accuracy: 0.38 - ETA: 1s - loss: 1.5072 - accuracy: 0.39 - ETA: 1s - loss: 1.5095 - accuracy: 0.39 - ETA: 1s - loss: 1.5096 - accuracy: 0.39 - ETA: 1s - loss: 1.4957 - accuracy: 0.39 - ETA: 0s - loss: 1.4858 - accuracy: 0.40 - ETA: 0s - loss: 1.4934 - accuracy: 0.39 - ETA: 0s - loss: 1.4906 - accuracy: 0.39 - ETA: 0s - loss: 1.4979 - accuracy: 0.38 - ETA: 0s - loss: 1.4979 - accuracy: 0.38 - ETA: 0s - loss: 1.5059 - accuracy: 0.38 - ETA: 0s - loss: 1.5007 - accuracy: 0.38 - ETA: 0s - loss: 1.4902 - accuracy: 0.39 - ETA: 0s - loss: 1.4898 - accuracy: 0.38 - ETA: 0s - loss: 1.4904 - accuracy: 0.38 - ETA: 0s - loss: 1.4887 - accuracy: 0.39 - ETA: 0s - loss: 1.4840 - accuracy: 0.39 - ETA: 0s - loss: 1.4791 - accuracy: 0.39 - ETA: 0s - loss: 1.4883 - accuracy: 0.39 - ETA: 0s - loss: 1.4916 - accuracy: 0.39 - 3s 3ms/step - loss: 1.4919 - accuracy: 0.3916 - val_loss: 1.8506 - val_accuracy: 0.3449\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.78088\n",
      "Epoch 10/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.4788 - accuracy: 0.34 - ETA: 2s - loss: 1.4608 - accuracy: 0.39 - ETA: 2s - loss: 1.4926 - accuracy: 0.40 - ETA: 2s - loss: 1.4648 - accuracy: 0.42 - ETA: 2s - loss: 1.4586 - accuracy: 0.43 - ETA: 2s - loss: 1.5125 - accuracy: 0.43 - ETA: 2s - loss: 1.5127 - accuracy: 0.42 - ETA: 1s - loss: 1.5006 - accuracy: 0.42 - ETA: 1s - loss: 1.4999 - accuracy: 0.41 - ETA: 1s - loss: 1.5055 - accuracy: 0.41 - ETA: 1s - loss: 1.4742 - accuracy: 0.42 - ETA: 1s - loss: 1.4808 - accuracy: 0.42 - ETA: 1s - loss: 1.4905 - accuracy: 0.41 - ETA: 1s - loss: 1.4839 - accuracy: 0.41 - ETA: 1s - loss: 1.4837 - accuracy: 0.41 - ETA: 1s - loss: 1.4828 - accuracy: 0.40 - ETA: 1s - loss: 1.4789 - accuracy: 0.39 - ETA: 1s - loss: 1.4965 - accuracy: 0.39 - ETA: 1s - loss: 1.4875 - accuracy: 0.38 - ETA: 1s - loss: 1.4941 - accuracy: 0.38 - ETA: 1s - loss: 1.5042 - accuracy: 0.37 - ETA: 0s - loss: 1.5056 - accuracy: 0.37 - ETA: 0s - loss: 1.5014 - accuracy: 0.38 - ETA: 0s - loss: 1.5009 - accuracy: 0.38 - ETA: 0s - loss: 1.4946 - accuracy: 0.38 - ETA: 0s - loss: 1.4884 - accuracy: 0.38 - ETA: 0s - loss: 1.4839 - accuracy: 0.38 - ETA: 0s - loss: 1.4814 - accuracy: 0.38 - ETA: 0s - loss: 1.4764 - accuracy: 0.39 - ETA: 0s - loss: 1.4876 - accuracy: 0.39 - ETA: 0s - loss: 1.4836 - accuracy: 0.39 - ETA: 0s - loss: 1.4854 - accuracy: 0.39 - ETA: 0s - loss: 1.4838 - accuracy: 0.39 - ETA: 0s - loss: 1.4821 - accuracy: 0.38 - ETA: 0s - loss: 1.4884 - accuracy: 0.38 - 3s 3ms/step - loss: 1.4882 - accuracy: 0.3845 - val_loss: 1.8507 - val_accuracy: 0.3449\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.78088\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 11/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.4259 - accuracy: 0.43 - ETA: 2s - loss: 1.3792 - accuracy: 0.43 - ETA: 2s - loss: 1.4390 - accuracy: 0.42 - ETA: 2s - loss: 1.4511 - accuracy: 0.42 - ETA: 2s - loss: 1.4456 - accuracy: 0.41 - ETA: 2s - loss: 1.4419 - accuracy: 0.42 - ETA: 2s - loss: 1.4783 - accuracy: 0.41 - ETA: 1s - loss: 1.5031 - accuracy: 0.40 - ETA: 1s - loss: 1.4978 - accuracy: 0.37 - ETA: 1s - loss: 1.4736 - accuracy: 0.40 - ETA: 1s - loss: 1.4712 - accuracy: 0.40 - ETA: 1s - loss: 1.4650 - accuracy: 0.41 - ETA: 1s - loss: 1.4706 - accuracy: 0.41 - ETA: 1s - loss: 1.4791 - accuracy: 0.41 - ETA: 1s - loss: 1.4875 - accuracy: 0.40 - ETA: 1s - loss: 1.4791 - accuracy: 0.40 - ETA: 1s - loss: 1.4779 - accuracy: 0.40 - ETA: 1s - loss: 1.4751 - accuracy: 0.41 - ETA: 1s - loss: 1.4724 - accuracy: 0.41 - ETA: 1s - loss: 1.4730 - accuracy: 0.40 - ETA: 1s - loss: 1.4727 - accuracy: 0.40 - ETA: 0s - loss: 1.4737 - accuracy: 0.40 - ETA: 0s - loss: 1.4740 - accuracy: 0.40 - ETA: 0s - loss: 1.4802 - accuracy: 0.39 - ETA: 0s - loss: 1.4770 - accuracy: 0.40 - ETA: 0s - loss: 1.4837 - accuracy: 0.39 - ETA: 0s - loss: 1.4816 - accuracy: 0.39 - ETA: 0s - loss: 1.4832 - accuracy: 0.39 - ETA: 0s - loss: 1.4781 - accuracy: 0.39 - ETA: 0s - loss: 1.4814 - accuracy: 0.39 - ETA: 0s - loss: 1.4827 - accuracy: 0.39 - ETA: 0s - loss: 1.4895 - accuracy: 0.39 - ETA: 0s - loss: 1.4935 - accuracy: 0.39 - ETA: 0s - loss: 1.4925 - accuracy: 0.38 - ETA: 0s - loss: 1.4881 - accuracy: 0.39 - 3s 3ms/step - loss: 1.4877 - accuracy: 0.3907 - val_loss: 1.8509 - val_accuracy: 0.3449\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.78088\n",
      "Epoch 12/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.6062 - accuracy: 0.25 - ETA: 2s - loss: 1.5954 - accuracy: 0.28 - ETA: 2s - loss: 1.5919 - accuracy: 0.27 - ETA: 2s - loss: 1.5568 - accuracy: 0.30 - ETA: 2s - loss: 1.5496 - accuracy: 0.32 - ETA: 2s - loss: 1.5425 - accuracy: 0.32 - ETA: 1s - loss: 1.5273 - accuracy: 0.33 - ETA: 1s - loss: 1.5210 - accuracy: 0.34 - ETA: 1s - loss: 1.5237 - accuracy: 0.34 - ETA: 1s - loss: 1.5084 - accuracy: 0.35 - ETA: 1s - loss: 1.5138 - accuracy: 0.34 - ETA: 1s - loss: 1.5083 - accuracy: 0.35 - ETA: 1s - loss: 1.5093 - accuracy: 0.35 - ETA: 1s - loss: 1.4978 - accuracy: 0.36 - ETA: 1s - loss: 1.4932 - accuracy: 0.37 - ETA: 1s - loss: 1.4885 - accuracy: 0.38 - ETA: 1s - loss: 1.4908 - accuracy: 0.38 - ETA: 1s - loss: 1.4840 - accuracy: 0.37 - ETA: 1s - loss: 1.4960 - accuracy: 0.37 - ETA: 1s - loss: 1.5085 - accuracy: 0.38 - ETA: 1s - loss: 1.5100 - accuracy: 0.38 - ETA: 0s - loss: 1.5055 - accuracy: 0.38 - ETA: 0s - loss: 1.4992 - accuracy: 0.38 - ETA: 0s - loss: 1.4939 - accuracy: 0.38 - ETA: 0s - loss: 1.4958 - accuracy: 0.38 - ETA: 0s - loss: 1.4923 - accuracy: 0.38 - ETA: 0s - loss: 1.4924 - accuracy: 0.38 - ETA: 0s - loss: 1.4907 - accuracy: 0.38 - ETA: 0s - loss: 1.4943 - accuracy: 0.38 - ETA: 0s - loss: 1.4899 - accuracy: 0.38 - ETA: 0s - loss: 1.4906 - accuracy: 0.38 - ETA: 0s - loss: 1.4903 - accuracy: 0.37 - ETA: 0s - loss: 1.4908 - accuracy: 0.37 - ETA: 0s - loss: 1.4922 - accuracy: 0.37 - ETA: 0s - loss: 1.4924 - accuracy: 0.37 - 3s 3ms/step - loss: 1.4917 - accuracy: 0.3756 - val_loss: 1.8510 - val_accuracy: 0.3449\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.78088\n",
      "Epoch 13/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.3407 - accuracy: 0.43 - ETA: 2s - loss: 1.4556 - accuracy: 0.39 - ETA: 2s - loss: 1.4595 - accuracy: 0.42 - ETA: 2s - loss: 1.4906 - accuracy: 0.40 - ETA: 2s - loss: 1.5007 - accuracy: 0.41 - ETA: 2s - loss: 1.4735 - accuracy: 0.40 - ETA: 2s - loss: 1.4785 - accuracy: 0.40 - ETA: 2s - loss: 1.4565 - accuracy: 0.43 - ETA: 2s - loss: 1.4588 - accuracy: 0.41 - ETA: 1s - loss: 1.4741 - accuracy: 0.41 - ETA: 1s - loss: 1.4767 - accuracy: 0.40 - ETA: 1s - loss: 1.4736 - accuracy: 0.40 - ETA: 1s - loss: 1.4856 - accuracy: 0.40 - ETA: 1s - loss: 1.5030 - accuracy: 0.38 - ETA: 1s - loss: 1.4963 - accuracy: 0.39 - ETA: 1s - loss: 1.4942 - accuracy: 0.38 - ETA: 1s - loss: 1.5011 - accuracy: 0.38 - ETA: 1s - loss: 1.4905 - accuracy: 0.38 - ETA: 1s - loss: 1.4898 - accuracy: 0.38 - ETA: 1s - loss: 1.4875 - accuracy: 0.39 - ETA: 1s - loss: 1.4922 - accuracy: 0.38 - ETA: 0s - loss: 1.4950 - accuracy: 0.38 - ETA: 0s - loss: 1.4916 - accuracy: 0.39 - ETA: 0s - loss: 1.4911 - accuracy: 0.38 - ETA: 0s - loss: 1.4910 - accuracy: 0.38 - ETA: 0s - loss: 1.4892 - accuracy: 0.38 - ETA: 0s - loss: 1.4874 - accuracy: 0.38 - ETA: 0s - loss: 1.4922 - accuracy: 0.38 - ETA: 0s - loss: 1.4895 - accuracy: 0.37 - ETA: 0s - loss: 1.4872 - accuracy: 0.38 - ETA: 0s - loss: 1.4819 - accuracy: 0.38 - ETA: 0s - loss: 1.4789 - accuracy: 0.38 - ETA: 0s - loss: 1.4766 - accuracy: 0.38 - ETA: 0s - loss: 1.4808 - accuracy: 0.38 - ETA: 0s - loss: 1.4795 - accuracy: 0.39 - 3s 3ms/step - loss: 1.4799 - accuracy: 0.3898 - val_loss: 1.8514 - val_accuracy: 0.3449\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.78088\n",
      "Epoch 14/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.4628 - accuracy: 0.40 - ETA: 2s - loss: 1.3834 - accuracy: 0.39 - ETA: 2s - loss: 1.3957 - accuracy: 0.40 - ETA: 2s - loss: 1.4405 - accuracy: 0.39 - ETA: 2s - loss: 1.4649 - accuracy: 0.36 - ETA: 1s - loss: 1.4486 - accuracy: 0.37 - ETA: 1s - loss: 1.4728 - accuracy: 0.36 - ETA: 1s - loss: 1.4594 - accuracy: 0.37 - ETA: 1s - loss: 1.4677 - accuracy: 0.37 - ETA: 1s - loss: 1.4844 - accuracy: 0.37 - ETA: 1s - loss: 1.4865 - accuracy: 0.37 - ETA: 1s - loss: 1.4808 - accuracy: 0.38 - ETA: 1s - loss: 1.4846 - accuracy: 0.37 - ETA: 1s - loss: 1.4964 - accuracy: 0.37 - ETA: 1s - loss: 1.5077 - accuracy: 0.36 - ETA: 1s - loss: 1.5034 - accuracy: 0.37 - ETA: 1s - loss: 1.5055 - accuracy: 0.37 - ETA: 1s - loss: 1.5022 - accuracy: 0.38 - ETA: 1s - loss: 1.5007 - accuracy: 0.38 - ETA: 1s - loss: 1.5032 - accuracy: 0.38 - ETA: 0s - loss: 1.4992 - accuracy: 0.39 - ETA: 0s - loss: 1.4933 - accuracy: 0.40 - ETA: 0s - loss: 1.4962 - accuracy: 0.40 - ETA: 0s - loss: 1.4998 - accuracy: 0.40 - ETA: 0s - loss: 1.5015 - accuracy: 0.40 - ETA: 0s - loss: 1.5045 - accuracy: 0.39 - ETA: 0s - loss: 1.4907 - accuracy: 0.40 - ETA: 0s - loss: 1.4903 - accuracy: 0.40 - ETA: 0s - loss: 1.4937 - accuracy: 0.40 - ETA: 0s - loss: 1.4950 - accuracy: 0.40 - ETA: 0s - loss: 1.4987 - accuracy: 0.40 - ETA: 0s - loss: 1.4974 - accuracy: 0.39 - ETA: 0s - loss: 1.4952 - accuracy: 0.39 - ETA: 0s - loss: 1.4940 - accuracy: 0.39 - ETA: 0s - loss: 1.4974 - accuracy: 0.39 - 3s 3ms/step - loss: 1.4966 - accuracy: 0.3916 - val_loss: 1.8513 - val_accuracy: 0.3449\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.78088\n",
      "Epoch 15/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.4418 - accuracy: 0.37 - ETA: 2s - loss: 1.4251 - accuracy: 0.34 - ETA: 2s - loss: 1.4530 - accuracy: 0.31 - ETA: 2s - loss: 1.4156 - accuracy: 0.35 - ETA: 2s - loss: 1.4200 - accuracy: 0.35 - ETA: 2s - loss: 1.4168 - accuracy: 0.35 - ETA: 1s - loss: 1.4290 - accuracy: 0.34 - ETA: 1s - loss: 1.4158 - accuracy: 0.37 - ETA: 1s - loss: 1.4336 - accuracy: 0.37 - ETA: 1s - loss: 1.4376 - accuracy: 0.38 - ETA: 1s - loss: 1.4432 - accuracy: 0.39 - ETA: 1s - loss: 1.4381 - accuracy: 0.38 - ETA: 1s - loss: 1.4446 - accuracy: 0.38 - ETA: 1s - loss: 1.4582 - accuracy: 0.38 - ETA: 1s - loss: 1.4717 - accuracy: 0.38 - ETA: 1s - loss: 1.4812 - accuracy: 0.37 - ETA: 1s - loss: 1.4801 - accuracy: 0.37 - ETA: 1s - loss: 1.4775 - accuracy: 0.37 - ETA: 1s - loss: 1.4756 - accuracy: 0.37 - ETA: 1s - loss: 1.4784 - accuracy: 0.37 - ETA: 0s - loss: 1.4847 - accuracy: 0.37 - ETA: 0s - loss: 1.4963 - accuracy: 0.37 - ETA: 0s - loss: 1.4904 - accuracy: 0.37 - ETA: 0s - loss: 1.4809 - accuracy: 0.37 - ETA: 0s - loss: 1.4894 - accuracy: 0.37 - ETA: 0s - loss: 1.4908 - accuracy: 0.37 - ETA: 0s - loss: 1.4979 - accuracy: 0.37 - ETA: 0s - loss: 1.5028 - accuracy: 0.37 - ETA: 0s - loss: 1.5065 - accuracy: 0.36 - ETA: 0s - loss: 1.5017 - accuracy: 0.36 - ETA: 0s - loss: 1.5013 - accuracy: 0.36 - ETA: 0s - loss: 1.4933 - accuracy: 0.37 - ETA: 0s - loss: 1.4886 - accuracy: 0.37 - ETA: 0s - loss: 1.4888 - accuracy: 0.37 - ETA: 0s - loss: 1.4895 - accuracy: 0.37 - 3s 3ms/step - loss: 1.4893 - accuracy: 0.3720 - val_loss: 1.8514 - val_accuracy: 0.3449\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.78088\n",
      "Epoch 16/50\n",
      "1121/1121 [==============================] - ETA: 2s - loss: 1.5487 - accuracy: 0.40 - ETA: 2s - loss: 1.4333 - accuracy: 0.39 - ETA: 2s - loss: 1.4598 - accuracy: 0.41 - ETA: 2s - loss: 1.5147 - accuracy: 0.37 - ETA: 2s - loss: 1.4889 - accuracy: 0.38 - ETA: 2s - loss: 1.4869 - accuracy: 0.36 - ETA: 2s - loss: 1.4715 - accuracy: 0.35 - ETA: 1s - loss: 1.4824 - accuracy: 0.33 - ETA: 1s - loss: 1.5009 - accuracy: 0.33 - ETA: 1s - loss: 1.5065 - accuracy: 0.33 - ETA: 1s - loss: 1.5061 - accuracy: 0.34 - ETA: 1s - loss: 1.5137 - accuracy: 0.34 - ETA: 1s - loss: 1.4904 - accuracy: 0.36 - ETA: 1s - loss: 1.4693 - accuracy: 0.36 - ETA: 1s - loss: 1.4712 - accuracy: 0.36 - ETA: 1s - loss: 1.4668 - accuracy: 0.36 - ETA: 1s - loss: 1.4705 - accuracy: 0.36 - ETA: 1s - loss: 1.4587 - accuracy: 0.37 - ETA: 1s - loss: 1.4706 - accuracy: 0.37 - ETA: 1s - loss: 1.4713 - accuracy: 0.36 - ETA: 0s - loss: 1.4623 - accuracy: 0.37 - ETA: 0s - loss: 1.4698 - accuracy: 0.37 - ETA: 0s - loss: 1.4794 - accuracy: 0.36 - ETA: 0s - loss: 1.4713 - accuracy: 0.36 - ETA: 0s - loss: 1.4721 - accuracy: 0.36 - ETA: 0s - loss: 1.4726 - accuracy: 0.37 - ETA: 0s - loss: 1.4779 - accuracy: 0.37 - ETA: 0s - loss: 1.4758 - accuracy: 0.37 - ETA: 0s - loss: 1.4755 - accuracy: 0.38 - ETA: 0s - loss: 1.4861 - accuracy: 0.37 - ETA: 0s - loss: 1.4826 - accuracy: 0.37 - ETA: 0s - loss: 1.4868 - accuracy: 0.37 - ETA: 0s - loss: 1.4902 - accuracy: 0.36 - ETA: 0s - loss: 1.4920 - accuracy: 0.36 - ETA: 0s - loss: 1.4871 - accuracy: 0.37 - 3s 3ms/step - loss: 1.4867 - accuracy: 0.3729 - val_loss: 1.8517 - val_accuracy: 0.3449\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.78088\n",
      "Epoch 17/50\n",
      "1024/1121 [==========================>...] - ETA: 2s - loss: 1.6103 - accuracy: 0.37 - ETA: 2s - loss: 1.4666 - accuracy: 0.35 - ETA: 2s - loss: 1.5140 - accuracy: 0.36 - ETA: 2s - loss: 1.5047 - accuracy: 0.35 - ETA: 2s - loss: 1.4828 - accuracy: 0.38 - ETA: 2s - loss: 1.4697 - accuracy: 0.41 - ETA: 1s - loss: 1.4701 - accuracy: 0.38 - ETA: 1s - loss: 1.4631 - accuracy: 0.38 - ETA: 1s - loss: 1.4559 - accuracy: 0.39 - ETA: 1s - loss: 1.4600 - accuracy: 0.38 - ETA: 1s - loss: 1.4739 - accuracy: 0.38 - ETA: 1s - loss: 1.4906 - accuracy: 0.37 - ETA: 1s - loss: 1.4885 - accuracy: 0.37 - ETA: 1s - loss: 1.4751 - accuracy: 0.37 - ETA: 1s - loss: 1.4649 - accuracy: 0.38 - ETA: 1s - loss: 1.4626 - accuracy: 0.38 - ETA: 1s - loss: 1.4675 - accuracy: 0.38 - ETA: 1s - loss: 1.4787 - accuracy: 0.38 - ETA: 1s - loss: 1.4848 - accuracy: 0.38 - ETA: 1s - loss: 1.4810 - accuracy: 0.37 - ETA: 1s - loss: 1.4751 - accuracy: 0.38 - ETA: 0s - loss: 1.4701 - accuracy: 0.38 - ETA: 0s - loss: 1.4730 - accuracy: 0.38 - ETA: 0s - loss: 1.4725 - accuracy: 0.39 - ETA: 0s - loss: 1.4798 - accuracy: 0.38 - ETA: 0s - loss: 1.4783 - accuracy: 0.39 - ETA: 0s - loss: 1.4735 - accuracy: 0.39 - ETA: 0s - loss: 1.4692 - accuracy: 0.39 - ETA: 0s - loss: 1.4736 - accuracy: 0.39 - ETA: 0s - loss: 1.4708 - accuracy: 0.39 - ETA: 0s - loss: 1.4735 - accuracy: 0.39 - ETA: 0s - loss: 1.4808 - accuracy: 0.3926"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-255-88b85244757c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m history = model.fit(X_train, to_categorical(y_train_coded), batch_size=batch_size, epochs=epochs, \n\u001b[1;32m----> 6\u001b[1;33m                     validation_data=[X_val, to_categorical(y_val_coded)], callbacks=[checkpoints, reduce_lr])\n\u001b[0m",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mapping_labels = {lab:code for code, lab in enumerate(np.unique(y_train))}\n",
    "y_train_coded = [mapping_labels[lab] for lab in y_train]\n",
    "y_val_coded = [mapping_labels[lab] for lab in y_val]\n",
    "\n",
    "history = model.fit(X_train, to_categorical(y_train_coded), batch_size=batch_size, epochs=epochs, \n",
    "                    validation_data=[X_val, to_categorical(y_val_coded)], callbacks=[checkpoints, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = (predictions.argmax(axis=1) != local_test.class_codes.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dicc = dict(np.array(train_hosts[[\"class\",\"class_codes\"]].drop_duplicates()))\n",
    "inv_dicc = {v:k for k, v in dicc.items()}\n",
    "pd.Series(predictions[indices].argmax(axis=1)).map(inv_dicc).value_counts(sort=False).plot(kind=\"bar\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_model_predicted_probas = predictions[indices][predictions[indices].argmax(axis=1) == 2]\n",
    "corresponding_real_classes = local_test.class_codes.values[indices][predictions[indices].argmax(axis=1) == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_probas = {i:[] for i in range(8)}\n",
    "for j, real_class in enumerate(local_test.class_codes.values[indices]) :\n",
    "    dico_probas[real_class].append(predictions[indices][j, real_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(15,7))\n",
    "for j in range(4):\n",
    "    for i in range(2) :\n",
    "        axs[i,j].set_title(\"{}\".format(inv_dicc[int(i*4)+j]))\n",
    "        axs[i,j].hist(dico_probas[int(i*4)+j], range=(0,0.5), edgecolor=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
